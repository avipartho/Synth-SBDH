{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a975d61-d4c1-42f4-882a-95e55917988f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import tqdm\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import datasets\n",
    "import nltk\n",
    "import torch\n",
    "import json\n",
    "import difflib\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datasets import load_metric\n",
    "from IPython.display import display,HTML\n",
    "from datasets import load_dataset, load_metric, concatenate_datasets\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from tqdm.auto import tqdm\n",
    "from collections import Counter\n",
    "from transformers import AutoTokenizer\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d843794-6c2f-4fbb-9449-c569364b194f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sbdh_map_dict = { # 12 final sbdh categories\n",
    "    'job insecurity': 'financial insecurity',\n",
    "    'substance abuse': 'substance abuse',\n",
    "    'social isolation': 'isolation or loss of relationship',\n",
    "    'psychiatric symptoms or disorders': 'psychiatric symptoms or disorders',\n",
    "    'housing insecurity': 'housing insecurity',\n",
    "    'financial insecurity': 'financial insecurity',\n",
    "    'patient disability': 'patient disability',\n",
    "    'pain': 'pain',\n",
    "    'loss of relationship': 'isolation or loss of relationship',\n",
    "    'transitions of care': 'transitions of care',\n",
    "    'food insecurity': 'food insecurity',\n",
    "    'violence': 'violence',\n",
    "    'barriers to care': 'barriers to care',\n",
    "    'legal problems': 'legal problems',\n",
    "    'physical isolation': 'isolation or loss of relationship'\n",
    "}\n",
    "\n",
    "sbdh_types = [\n",
    "    'Job Insecurity', 'Substance Abuse', 'Social Isolation', 'Psychiatric Symptoms or Disorders', 'Housing Insecurity', 'Financial Insecurity', \n",
    "    'Patient Disability', 'Pain', 'Loss of Relationship', 'Transitions of Care', 'Food Insecurity', 'Violence', 'Barriers to Care', 'Legal Problems', 'Physical Isolation'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84ff5e7-0a87-40f1-b863-bacbcb37b229",
   "metadata": {},
   "source": [
    "# V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2c660c7e-9646-4065-bdfb-31c18dfb763f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "openai.api_key = '' # INSERT YOUR API KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "75b67036-0112-49be-a95c-5df1ef6acd1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"gpt-4-0613\" # \"gpt-4-0314\"\n",
    "temperature = 0\n",
    "client = openai.OpenAI(api_key=openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "15f82dc1-8b07-4688-b80c-314b1f6c0769",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('prompts/examples.txt') as f: \n",
    "    examples = f.readlines()\n",
    "\n",
    "example_dict_list = []\n",
    "temp_dict = {}\n",
    "for idx,i in enumerate(examples):\n",
    "    if i!='\\n':\n",
    "        temp_dict[i.split(': ')[0].strip()] = ' '.join(i.split(': ')[1:]).strip()\n",
    "    if len(temp_dict)==3: \n",
    "        example_dict_list += [temp_dict]\n",
    "        temp_dict = {}\n",
    "\n",
    "examples_df = pd.DataFrame(example_dict_list)\n",
    "examples_df['Textspan'] = examples_df.apply(lambda x: ' || '.join([i.split(', ')[0][1:] for i in x['Annotations'].split(' || ')]), axis=1)\n",
    "examples_df['SBDH'] = examples_df.apply(lambda x: ' || '.join([i.split(', ')[1] for i in x['Annotations'].split(' || ')]), axis=1)\n",
    "examples_df['Presence'] = examples_df.apply(lambda x: ' || '.join([i.split(', ')[2] for i in x['Annotations'].split(' || ')]), axis=1)\n",
    "examples_df['Period'] = examples_df.apply(lambda x: ' || '.join([i.split(', ')[3][:-1] for i in x['Annotations'].split(' || ')]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "4473569a-a8d6-4445-abc4-873d04859571",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Housing Insecurity': 15, 'Psychiatric Symptoms or Disorders': 10, 'Financial Insecurity': 9, 'Substance Abuse': 9, 'Transitions of Care': 9, 'Violence': 8, 'Job Insecurity': 8, 'Legal Problems': 7, 'Social Isolation': 7, 'Loss of Relationship': 6, 'Food Insecurity': 5, 'Pain': 4, 'Barriers to Care': 3, 'Patient Disability': 3, 'Physical Isolation': 2})\n"
     ]
    }
   ],
   "source": [
    "# check if annotations are in correct format\n",
    "anns = []\n",
    "for ann in examples_df['Annotations'].tolist():\n",
    "    # print([len(i.split(', ')) for i in ann.split(' || ')])\n",
    "    anns+=[i.split(', ')[1] for i in ann.split(' || ')]\n",
    "print(Counter(anns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "89964152-bbb9-4a65-b4e1-d90eb9f33d91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Thought processes</th>\n",
       "      <th>Annotations</th>\n",
       "      <th>Textspan</th>\n",
       "      <th>SBDH</th>\n",
       "      <th>Presence</th>\n",
       "      <th>Period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Unemployed but reported is seeking work.</td>\n",
       "      <td>Patient is currently unemployed || Patient is ...</td>\n",
       "      <td>(unemployed, Job Insecurity, yes, current) || ...</td>\n",
       "      <td>unemployed || seeking work</td>\n",
       "      <td>Job Insecurity || Job Insecurity</td>\n",
       "      <td>yes || yes</td>\n",
       "      <td>current || current</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Patient's Seroquel dose remains the same.</td>\n",
       "      <td>Seroquel dosage did not change, so no transiti...</td>\n",
       "      <td>(does remains the same, Transitions of Care, n...</td>\n",
       "      <td>does remains the same</td>\n",
       "      <td>Transitions of Care</td>\n",
       "      <td>no</td>\n",
       "      <td>current</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Admitting diagnoses/problems: abdominal pain.</td>\n",
       "      <td>Patient has abdominal pain.</td>\n",
       "      <td>(pain, Pain, yes, current)</td>\n",
       "      <td>pain</td>\n",
       "      <td>Pain</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>She is keeping herself busy attending church a...</td>\n",
       "      <td>She attends church, where she is with others. ...</td>\n",
       "      <td>(attending church, Social Isolation, no, curre...</td>\n",
       "      <td>attending church || individuals who are suppor...</td>\n",
       "      <td>Social Isolation || Social Isolation</td>\n",
       "      <td>no || no</td>\n",
       "      <td>current || current</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Patient says she was incarcerated for parole v...</td>\n",
       "      <td>Patient was incarcerated for a violation of th...</td>\n",
       "      <td>(incarcerated, Legal Problems, yes, history) |...</td>\n",
       "      <td>incarcerated || parole violation || armed robb...</td>\n",
       "      <td>Legal Problems || Legal Problems || Legal Prob...</td>\n",
       "      <td>yes || yes || yes</td>\n",
       "      <td>history || history || history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Veteran is reporting unwanted thoughts of harm...</td>\n",
       "      <td>Thoughts of harming others is considered viole...</td>\n",
       "      <td>(thoughts of harming, Violence, yes, current) ...</td>\n",
       "      <td>thoughts of harming || jumped me</td>\n",
       "      <td>Violence || Violence</td>\n",
       "      <td>yes || yes</td>\n",
       "      <td>current || current</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Veteran no longer requires a walker for ambula...</td>\n",
       "      <td>Not requiring assistive devices shows that pat...</td>\n",
       "      <td>(walker, Patient Disability, no, current)</td>\n",
       "      <td>walker</td>\n",
       "      <td>Patient Disability</td>\n",
       "      <td>no</td>\n",
       "      <td>current</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Is the patient \"marginally housed\"? No. Has pa...</td>\n",
       "      <td>Patient is not currently \"marginally housed\". ...</td>\n",
       "      <td>(marginally housed, Housing Insecurity, no, cu...</td>\n",
       "      <td>marginally housed || homeless</td>\n",
       "      <td>Housing Insecurity || Housing Insecurity</td>\n",
       "      <td>no || no</td>\n",
       "      <td>current || current</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Patient's pain has been addressed by patient's...</td>\n",
       "      <td>Patient is experiencing pain. || Patient's pai...</td>\n",
       "      <td>(pain, Pain, yes, current) || (pain, Pain, yes...</td>\n",
       "      <td>pain || pain</td>\n",
       "      <td>Pain || Pain</td>\n",
       "      <td>yes || yes</td>\n",
       "      <td>current || current</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Veteran was evicted from his most recent apart...</td>\n",
       "      <td>Eviction is categorized as housing insecurity....</td>\n",
       "      <td>(was evicted, Housing Insecurity, yes, current...</td>\n",
       "      <td>was evicted || most recent apartment || non-pa...</td>\n",
       "      <td>Housing Insecurity || Housing Insecurity || Ho...</td>\n",
       "      <td>yes || yes || yes || yes || yes</td>\n",
       "      <td>current || current || current || current || cu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Text  \\\n",
       "30           Unemployed but reported is seeking work.   \n",
       "37          Patient's Seroquel dose remains the same.   \n",
       "27      Admitting diagnoses/problems: abdominal pain.   \n",
       "4   She is keeping herself busy attending church a...   \n",
       "10  Patient says she was incarcerated for parole v...   \n",
       "25  Veteran is reporting unwanted thoughts of harm...   \n",
       "28  Veteran no longer requires a walker for ambula...   \n",
       "11  Is the patient \"marginally housed\"? No. Has pa...   \n",
       "38  Patient's pain has been addressed by patient's...   \n",
       "31  Veteran was evicted from his most recent apart...   \n",
       "\n",
       "                                    Thought processes  \\\n",
       "30  Patient is currently unemployed || Patient is ...   \n",
       "37  Seroquel dosage did not change, so no transiti...   \n",
       "27                        Patient has abdominal pain.   \n",
       "4   She attends church, where she is with others. ...   \n",
       "10  Patient was incarcerated for a violation of th...   \n",
       "25  Thoughts of harming others is considered viole...   \n",
       "28  Not requiring assistive devices shows that pat...   \n",
       "11  Patient is not currently \"marginally housed\". ...   \n",
       "38  Patient is experiencing pain. || Patient's pai...   \n",
       "31  Eviction is categorized as housing insecurity....   \n",
       "\n",
       "                                          Annotations  \\\n",
       "30  (unemployed, Job Insecurity, yes, current) || ...   \n",
       "37  (does remains the same, Transitions of Care, n...   \n",
       "27                         (pain, Pain, yes, current)   \n",
       "4   (attending church, Social Isolation, no, curre...   \n",
       "10  (incarcerated, Legal Problems, yes, history) |...   \n",
       "25  (thoughts of harming, Violence, yes, current) ...   \n",
       "28          (walker, Patient Disability, no, current)   \n",
       "11  (marginally housed, Housing Insecurity, no, cu...   \n",
       "38  (pain, Pain, yes, current) || (pain, Pain, yes...   \n",
       "31  (was evicted, Housing Insecurity, yes, current...   \n",
       "\n",
       "                                             Textspan  \\\n",
       "30                         unemployed || seeking work   \n",
       "37                              does remains the same   \n",
       "27                                               pain   \n",
       "4   attending church || individuals who are suppor...   \n",
       "10  incarcerated || parole violation || armed robb...   \n",
       "25                   thoughts of harming || jumped me   \n",
       "28                                             walker   \n",
       "11                      marginally housed || homeless   \n",
       "38                                       pain || pain   \n",
       "31  was evicted || most recent apartment || non-pa...   \n",
       "\n",
       "                                                 SBDH  \\\n",
       "30                   Job Insecurity || Job Insecurity   \n",
       "37                                Transitions of Care   \n",
       "27                                               Pain   \n",
       "4                Social Isolation || Social Isolation   \n",
       "10  Legal Problems || Legal Problems || Legal Prob...   \n",
       "25                               Violence || Violence   \n",
       "28                                 Patient Disability   \n",
       "11           Housing Insecurity || Housing Insecurity   \n",
       "38                                       Pain || Pain   \n",
       "31  Housing Insecurity || Housing Insecurity || Ho...   \n",
       "\n",
       "                           Presence  \\\n",
       "30                       yes || yes   \n",
       "37                               no   \n",
       "27                              yes   \n",
       "4                          no || no   \n",
       "10                yes || yes || yes   \n",
       "25                       yes || yes   \n",
       "28                               no   \n",
       "11                         no || no   \n",
       "38                       yes || yes   \n",
       "31  yes || yes || yes || yes || yes   \n",
       "\n",
       "                                               Period  \n",
       "30                                 current || current  \n",
       "37                                            current  \n",
       "27                                            current  \n",
       "4                                  current || current  \n",
       "10                      history || history || history  \n",
       "25                                 current || current  \n",
       "28                                            current  \n",
       "11                                 current || current  \n",
       "38                                 current || current  \n",
       "31  current || current || current || current || cu...  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples_df.sample(n=10, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb87d725-3bf6-4324-8f07-73f3209f106a",
   "metadata": {},
   "source": [
    "## All in One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "id": "d65a9af8-43d6-459d-a05d-7a281006ad4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8012398bcafd4d9caae36e8cd2d4e3d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/602 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid JSON format.60\n",
      "Invalid JSON format.1691\n",
      "Invalid JSON format.4563\n",
      "Invalid JSON format.5313\n",
      "Generated examples: 5973\r"
     ]
    }
   ],
   "source": [
    "def encode_prompt(sample_example_df):\n",
    "    \"\"\"Encode multiple prompt instructions into a single string.\"\"\"\n",
    "    prompt = ''\n",
    "    for idx in range(sample_example_df.shape[0]):\n",
    "        prompt += f\"Example {idx+1}.\\n\"\n",
    "        prompt += f\"Text: {sample_example_df.iloc[idx]['Text']}\\n\"\n",
    "        prompt += f\"Textspan: {sample_example_df.iloc[idx]['Textspan']}\\n\"\n",
    "        prompt += f\"Reasoning: {sample_example_df.iloc[idx]['Thought processes']}\\n\"\n",
    "        prompt += f\"SBDH: {sample_example_df.iloc[idx]['SBDH']}\\n\"\n",
    "        prompt += f\"Presence: {sample_example_df.iloc[idx]['Presence']}\\n\"\n",
    "        prompt += f\"Period: {sample_example_df.iloc[idx]['Period']}\\n\\n\"\n",
    "    return prompt.strip()\n",
    "\n",
    "prompt_system = 'You are an expert in healthcare science and clinical text. Respond to user questions wisely.'\n",
    "with open('prompts/sdoh_prompt.txt') as f: prompt_user = f.read()\n",
    "prompt_suffix = \"\"\"Format examples as a valid JSON with the following structure:\n",
    "[\n",
    "    {\n",
    "        'Text':..., \n",
    "        'Annotations': [\n",
    "            {\n",
    "                'Textspan':...,\n",
    "                'Reasoning':...,\n",
    "                'SBDH':...,\n",
    "                'Presence':...,\n",
    "                'Period':...,\n",
    "            },\n",
    "            ...\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        'Text':...,\n",
    "        'Annotations': [\n",
    "            {\n",
    "                'Textspan':...,\n",
    "                'Reasoning':...,\n",
    "                'SBDH':...,\n",
    "                'Presence':...,\n",
    "                'Period':...,\n",
    "            },\n",
    "            ...\n",
    "        ]\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "synth_sbdh_data, invalid_synth_sbdh_data, prompts = [], [], []\n",
    "start_time = time.time()\n",
    "num_few_shot_examples, num_examples_to_gen_at_once, num_examples_to_generate = 10, 10, 6000\n",
    "# i = 0\n",
    "for i in tqdm(range(num_examples_to_generate//num_examples_to_gen_at_once+2)):\n",
    "    final_prompt = prompt_user.strip().replace('{##examples##}',encode_prompt(examples_df.sample(n=num_few_shot_examples,random_state=i)))\\\n",
    "    .replace('{##example_no##}',str(num_examples_to_gen_at_once))+' '+prompt_suffix\n",
    "    prompts += [final_prompt]\n",
    "    messages = [{\"role\": \"system\", \"content\": prompt_system},\n",
    "                {\"role\": \"user\", \"content\": final_prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=messages,\n",
    "        temperature=.8,\n",
    "        # response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "    gen_txt = response.choices[0].message.content\n",
    "    gen_txt = re.sub(\"(?<=[a-z])'(?=[a-z])\", \"\\\\'\",gen_txt) # Add escape character before apostrophes to avoid formatting error\n",
    "    try:synth_sbdh_data += json.loads(json.dumps(eval(gen_txt)))\n",
    "    except: \n",
    "        invalid_synth_sbdh_data += [gen_txt]\n",
    "        print('Invalid JSON format.')\n",
    "    \n",
    "    # i += 1\n",
    "    # print(f'Iteration: {i}, elapsed time: {(time.time()-start_time)/60} minutes, generated examples: {len(synth_sbdh_data)}')\n",
    "    print(f'Generated examples: {len(synth_sbdh_data)}',end='\\r')\n",
    "    \n",
    "    with open('synth_data_gpt4/synth_data_aio_4.json','w') as f:\n",
    "        json.dump(synth_sbdh_data, f)\n",
    "        \n",
    "    if len(synth_sbdh_data)>=num_examples_to_generate: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "67a2ed90-7dc9-4968-a509-3199f651310a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before >> \n",
      "Examples: 14,244 || annotations: 22,459 || ann/exmpales: 1.58\n",
      "Average text length: 13.27 words\n",
      "Average textspan length: 4.06 words\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8544a2951dd45708609777100a3d6ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13554 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After >> \n",
      "Examples: 13,554 || annotations: 21,661 || ann/exmpales: 1.60\n",
      "Average text length: 13.26 words\n",
      "Average textspan length: 3.93 words\n",
      "SBDH                             \n",
      "job insecurity                       2256\n",
      "substance abuse                      2130\n",
      "social isolation                     2008\n",
      "psychiatric symptoms or disorders    1941\n",
      "housing insecurity                   1834\n",
      "financial insecurity                 1673\n",
      "patient disability                   1514\n",
      "pain                                 1446\n",
      "loss of relationship                 1334\n",
      "transitions of care                  1311\n",
      "food insecurity                      1029\n",
      "violence                              985\n",
      "barriers to care                      862\n",
      "legal problems                        760\n",
      "physical isolation                    578\n",
      "dtype: int64\n",
      "Presence  Period \n",
      "yes       current    18547\n",
      "          history     2477\n",
      "no        current      521\n",
      "          history      116\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load synthetic data\n",
    "synth_data = []\n",
    "for i in range(1,5):    \n",
    "    with open(f'synth_data_gpt4/synth_data_aio_{i}.json') as f:\n",
    "        synth_data += json.load(f)\n",
    "\n",
    "# Filter out examples with ill-formatted annotations\n",
    "sents, anns = [], []\n",
    "for idx,i in enumerate(synth_data):\n",
    "    for ann in i['Annotations']:\n",
    "        ann['Text']=i['Text'] \n",
    "        ann['idx']=idx\n",
    "    sents += [i['Text']]\n",
    "    anns += i['Annotations']\n",
    "\n",
    "# print(f'Total examples: {len(sents)}, total annotations: {len(anns)}')\n",
    "anns_df = pd.DataFrame(anns)\n",
    "\n",
    "# stats (before)\n",
    "print(f\"Before >> \\nExamples: {anns_df['idx'].nunique():,} || annotations: {anns_df.shape[0]:,} || ann/exmpales: {anns_df.shape[0]/anns_df['idx'].nunique():.2f}\")\n",
    "text_length = [len(sent.split(' ')) for sent in sents]\n",
    "print(f'Average text length: {sum(text_length)/len(text_length):.2f} words')\n",
    "print(f\"Average textspan length: {anns_df['Textspan'].apply(lambda x: len(x.split(' '))).mean():.2f} words\")\n",
    "\n",
    "# Filter out ill-formatted examples\n",
    "sbdh_types = list(map(str.lower,sbdh_types))\n",
    "anns_df['SBDH'] = anns_df['SBDH'].astype(str).str.lower()\n",
    "anns_df['Presence'] = anns_df['Presence'].astype(str).str.lower()\n",
    "anns_df['Period'] = anns_df['Period'].astype(str).str.lower()\n",
    "anns_df = anns_df[anns_df['SBDH'].isin(sbdh_types) & anns_df['Presence'].isin(['yes','no']) & anns_df['Period'].isin(['current','history'])]\n",
    "anns_df = anns_df[anns_df.apply(lambda x: x['Textspan'] in x['Text'],axis=1)]\n",
    "\n",
    "# merge annotations into single row\n",
    "anns_df_collapsed = pd.DataFrame(anns_df['idx'].unique(),columns=['idx']).copy()\n",
    "for col in ['Textspan', 'Reasoning', 'SBDH', 'Presence', 'Period', 'Text']: \n",
    "    anns_df_collapsed[col] = 0\n",
    "    \n",
    "for i,idx in tqdm(enumerate(anns_df['idx'].unique()),total=anns_df_collapsed.shape[0]):\n",
    "    temp_df = anns_df[anns_df['idx']==idx].copy()\n",
    "    assert temp_df['Text'].nunique()==1\n",
    "    for col in ['Textspan', 'Reasoning', 'SBDH', 'Presence', 'Period']:\n",
    "        anns_df_collapsed.loc[i,col] = ' || '.join(temp_df[col].tolist())\n",
    "    anns_df_collapsed.loc[i,'Text'] = temp_df.iloc[0]['Text']\n",
    "\n",
    "# stats (after)\n",
    "print(f\"After >> \\nExamples: {anns_df['idx'].nunique():,} || annotations: {anns_df.shape[0]:,} || ann/exmpales: {anns_df.shape[0]/anns_df['idx'].nunique():.2f}\")\n",
    "print(f\"Average text length: {anns_df_collapsed['Text'].apply(lambda x: len(x.split(' '))).mean():.2f} words\")\n",
    "print(f\"Average textspan length: {anns_df['Textspan'].apply(lambda x: len(x.split(' '))).mean():.2f} words\")\n",
    "\n",
    "print(anns_df[['SBDH']].value_counts())\n",
    "# print(anns_df[['Presence']].value_counts())\n",
    "# print(anns_df[['Period']].value_counts())\n",
    "print(anns_df[['Presence','Period']].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90726791-c53b-4728-9003-f051c41bf9cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Textspan</th>\n",
       "      <th>Reasoning</th>\n",
       "      <th>SBDH</th>\n",
       "      <th>Presence</th>\n",
       "      <th>Period</th>\n",
       "      <th>Text</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mother recently passed away</td>\n",
       "      <td>Patient has lost a close relationship due to d...</td>\n",
       "      <td>loss of relationship</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "      <td>Patient's mother recently passed away, causing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>emotional distress</td>\n",
       "      <td>The patient is experiencing emotional difficul...</td>\n",
       "      <td>psychiatric symptoms or disorders</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "      <td>Patient's mother recently passed away, causing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>back pain</td>\n",
       "      <td>The patient is experiencing physical discomfort.</td>\n",
       "      <td>pain</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "      <td>Veteran continues to have back pain and has be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>prescribed opioids</td>\n",
       "      <td>The patient has been provided with prescriptio...</td>\n",
       "      <td>substance abuse</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "      <td>Veteran continues to have back pain and has be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lives alone</td>\n",
       "      <td>The patient is living without companionship or...</td>\n",
       "      <td>social isolation</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "      <td>Patient lives alone in a high-crime neighborho...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Textspan  \\\n",
       "0  mother recently passed away   \n",
       "1           emotional distress   \n",
       "2                    back pain   \n",
       "3           prescribed opioids   \n",
       "4                  lives alone   \n",
       "\n",
       "                                           Reasoning  \\\n",
       "0  Patient has lost a close relationship due to d...   \n",
       "1  The patient is experiencing emotional difficul...   \n",
       "2   The patient is experiencing physical discomfort.   \n",
       "3  The patient has been provided with prescriptio...   \n",
       "4  The patient is living without companionship or...   \n",
       "\n",
       "                                SBDH Presence   Period  \\\n",
       "0               loss of relationship      yes  current   \n",
       "1  psychiatric symptoms or disorders      yes  current   \n",
       "2                               pain      yes  current   \n",
       "3                    substance abuse      yes  current   \n",
       "4                   social isolation      yes  current   \n",
       "\n",
       "                                                Text  idx  \n",
       "0  Patient's mother recently passed away, causing...    0  \n",
       "1  Patient's mother recently passed away, causing...    0  \n",
       "2  Veteran continues to have back pain and has be...    1  \n",
       "3  Veteran continues to have back pain and has be...    1  \n",
       "4  Patient lives alone in a high-crime neighborho...    2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>Textspan</th>\n",
       "      <th>Reasoning</th>\n",
       "      <th>SBDH</th>\n",
       "      <th>Presence</th>\n",
       "      <th>Period</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>mother recently passed away || emotional distress</td>\n",
       "      <td>Patient has lost a close relationship due to d...</td>\n",
       "      <td>loss of relationship || psychiatric symptoms o...</td>\n",
       "      <td>yes || yes</td>\n",
       "      <td>current || current</td>\n",
       "      <td>Patient's mother recently passed away, causing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>back pain || prescribed opioids</td>\n",
       "      <td>The patient is experiencing physical discomfor...</td>\n",
       "      <td>pain || substance abuse</td>\n",
       "      <td>yes || yes</td>\n",
       "      <td>current || current</td>\n",
       "      <td>Veteran continues to have back pain and has be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>lives alone || high-crime neighborhood</td>\n",
       "      <td>The patient is living without companionship or...</td>\n",
       "      <td>social isolation || violence</td>\n",
       "      <td>yes || yes</td>\n",
       "      <td>current || current</td>\n",
       "      <td>Patient lives alone in a high-crime neighborho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>was laid off || struggling to pay for medical ...</td>\n",
       "      <td>The patient has lost their job, indicating job...</td>\n",
       "      <td>job insecurity || financial insecurity</td>\n",
       "      <td>yes || yes</td>\n",
       "      <td>current || current</td>\n",
       "      <td>Patient was laid off and is now struggling to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>difficulty in accessing fresh produce</td>\n",
       "      <td>Patient lacks access to fresh, healthy food, i...</td>\n",
       "      <td>food insecurity</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "      <td>Patient reports difficulty in accessing fresh ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx                                           Textspan  \\\n",
       "0    0  mother recently passed away || emotional distress   \n",
       "1    1                    back pain || prescribed opioids   \n",
       "2    2             lives alone || high-crime neighborhood   \n",
       "3    3  was laid off || struggling to pay for medical ...   \n",
       "4    4              difficulty in accessing fresh produce   \n",
       "\n",
       "                                           Reasoning  \\\n",
       "0  Patient has lost a close relationship due to d...   \n",
       "1  The patient is experiencing physical discomfor...   \n",
       "2  The patient is living without companionship or...   \n",
       "3  The patient has lost their job, indicating job...   \n",
       "4  Patient lacks access to fresh, healthy food, i...   \n",
       "\n",
       "                                                SBDH    Presence  \\\n",
       "0  loss of relationship || psychiatric symptoms o...  yes || yes   \n",
       "1                            pain || substance abuse  yes || yes   \n",
       "2                       social isolation || violence  yes || yes   \n",
       "3             job insecurity || financial insecurity  yes || yes   \n",
       "4                                    food insecurity         yes   \n",
       "\n",
       "               Period                                               Text  \n",
       "0  current || current  Patient's mother recently passed away, causing...  \n",
       "1  current || current  Veteran continues to have back pain and has be...  \n",
       "2  current || current  Patient lives alone in a high-crime neighborho...  \n",
       "3  current || current  Patient was laid off and is now struggling to ...  \n",
       "4             current  Patient reports difficulty in accessing fresh ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(anns_df.head())\n",
    "display(anns_df_collapsed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee891874-5e0a-4020-b42c-d8b965eaefac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avijit/miniconda3/envs/lt/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86e7cd15e79140c48c2a5a412d685088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13554 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13554,) 8767\n"
     ]
    }
   ],
   "source": [
    "# check for similar looking sentences\n",
    "rouge = load_metric(\"rouge\")\n",
    "results, eligible_idxs = [], []\n",
    "sents = anns_df_collapsed['Text'].tolist()\n",
    "for idx,sent in tqdm(enumerate(sents),total=len(sents)):\n",
    "    res = rouge.compute(predictions=[sent]*len(sents[:idx+1]),references=sents[:idx+1],use_aggregator=False)\n",
    "    res = [i.fmeasure for i in res['rougeL']]\n",
    "    results += [res]\n",
    "    \n",
    "    r = res[:] # deep copy\n",
    "    del r[idx] # delete rouge score with the sentence itself\n",
    "    if idx ==0 or max(r)<0.7: eligible_idxs += [idx] \n",
    "\n",
    "results = np.array(results)\n",
    "print(results.shape,len(eligible_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "ca629a12-51ef-4b05-8c5b-7ffe93b094cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"eligible_idxs.json\", \"w\") as fp:\n",
    "    json.dump(eligible_idxs, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a48a20c-4cdd-4a58-920f-d3e6cf7f74dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8767\n"
     ]
    }
   ],
   "source": [
    "synth_sbdh_data_filtered = []\n",
    "for i in eligible_idxs:\n",
    "    synth_sbdh_data_filtered += [synth_data[anns_df_collapsed.loc[i,'idx']]]\n",
    "print(len(synth_sbdh_data_filtered))\n",
    "\n",
    "with open('synth_data_gpt4/synth_data_aio_filtered_8767.json','w') as f:\n",
    "    json.dump(synth_sbdh_data_filtered, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ebd6ae-5ba1-4726-b771-89c56d3eb914",
   "metadata": {},
   "source": [
    "### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b65a0598-7e4c-4e7c-95a4-6541051b2fe4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8767\n",
      "Training examples: 6,136, val examples: 876, test examples: 1,755\n",
      "Total examples: 8,767; total annotations: 14,420\n",
      "Total examples: 8,767; total annotations: 14,342\n"
     ]
    }
   ],
   "source": [
    "with open('synth_data_gpt4/synth_data_aio_filtered_8767.json') as f:\n",
    "    synth_sbdh_data_filtered = json.load(f)\n",
    "print(len(synth_sbdh_data_filtered))\n",
    "\n",
    "num_train_examples = int(len(synth_sbdh_data_filtered)*.7)\n",
    "num_val_examples = int(len(synth_sbdh_data_filtered)*.1)\n",
    "num_test_examples = len(synth_sbdh_data_filtered) - num_train_examples - num_val_examples\n",
    "print(f\"Training examples: {num_train_examples:,}, val examples: {num_val_examples:,}, test examples: {num_test_examples:,}\")\n",
    "\n",
    "random.seed(0)\n",
    "random.shuffle(synth_sbdh_data_filtered)\n",
    "sents, anns = [], []\n",
    "for idx,i in enumerate(synth_sbdh_data_filtered):\n",
    "    sents += [i['Text']]\n",
    "    for ann_idx,_ in enumerate(i['Annotations']):\n",
    "        ann = i['Annotations'][ann_idx].copy()\n",
    "        ann['ex_no'] = idx\n",
    "        ann['ann_no'] = ann_idx\n",
    "        anns += [ann]\n",
    "print(f'Total examples: {len(sents):,}; total annotations: {len(anns):,}')\n",
    "anns_df = pd.DataFrame(anns)\n",
    "\n",
    "# Filter out ill-formatted examples, there SHOULDN'T BE ANY SUCH DATA here. Something happened while savig 'synth_data_aio_filtered_8767.json'\n",
    "sbdh_types = list(map(str.lower,sbdh_types))\n",
    "anns_df['SBDH'] = anns_df['SBDH'].astype(str).str.lower()\n",
    "anns_df['Presence'] = anns_df['Presence'].astype(str).str.lower()\n",
    "anns_df['Period'] = anns_df['Period'].astype(str).str.lower()\n",
    "# anns_df['Correct'] = anns_df['Correct'].astype(str).str.lower()\n",
    "anns_df = anns_df[anns_df['SBDH'].isin(sbdh_types) & anns_df['Presence'].isin(['yes','no']) & anns_df['Period'].isin(['current','history'])]\n",
    "anns_df = anns_df[anns_df.apply(lambda x: x['Textspan'] in x['Text'],axis=1)]\n",
    "print(f\"Total examples: {anns_df['idx'].nunique():,}; total annotations: {anns_df.shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eafa221f-e0ca-498a-938d-afc2ee46afa6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81be9cfc1cb24878b84a44a4b13de5db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8767 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples: 8,767 || annotations: 14,342 || ann/exmpales: 1.64\n",
      "Average text length: 13.70 words\n",
      "Average textspan length: 3.96 words\n"
     ]
    }
   ],
   "source": [
    "# merge annotations of same text into single row\n",
    "anns_df_collapsed = pd.DataFrame(anns_df['idx'].unique(),columns=['idx']).copy()\n",
    "for col in ['ex_no','Text','Textspan', 'Reasoning', 'SBDH', 'Presence', 'Period']: \n",
    "    anns_df_collapsed[col] = 0\n",
    "    \n",
    "for i,idx in tqdm(enumerate(anns_df['idx'].unique()),total=anns_df_collapsed.shape[0]):\n",
    "    temp_df = anns_df[anns_df['idx']==idx].copy()\n",
    "    assert temp_df['Text'].nunique()==1\n",
    "    for col in ['Textspan', 'Reasoning', 'SBDH', 'Presence', 'Period']:\n",
    "        anns_df_collapsed.loc[i,col] = ' || '.join(temp_df[col].tolist())\n",
    "    anns_df_collapsed.loc[i,'Text'] = temp_df.iloc[0]['Text']\n",
    "    anns_df_collapsed.loc[i,'ex_no'] = temp_df.iloc[0]['ex_no']\n",
    "    \n",
    "# stats (after)\n",
    "print(f\"Examples: {anns_df['idx'].nunique():,} || annotations: {anns_df.shape[0]:,} || ann/exmpales: {anns_df.shape[0]/anns_df['idx'].nunique():.2f}\")\n",
    "print(f\"Average text length: {anns_df_collapsed['Text'].apply(lambda x: len(x.split(' '))).mean():.2f} words\")\n",
    "print(f\"Average textspan length: {anns_df['Textspan'].apply(lambda x: len(x.split(' '))).mean():.2f} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb2c2495-6fbd-406e-9b23-975e47438543",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>ex_no</th>\n",
       "      <th>Text</th>\n",
       "      <th>Textspan</th>\n",
       "      <th>Reasoning</th>\n",
       "      <th>SBDH</th>\n",
       "      <th>Presence</th>\n",
       "      <th>Period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10742</td>\n",
       "      <td>0</td>\n",
       "      <td>He has suffered from chronic pain for several ...</td>\n",
       "      <td>suffered from chronic pain || not addicted to ...</td>\n",
       "      <td>The patient is suffering from chronic pain. ||...</td>\n",
       "      <td>pain || substance abuse</td>\n",
       "      <td>yes || no</td>\n",
       "      <td>current || current</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8855</td>\n",
       "      <td>1</td>\n",
       "      <td>Patient feels undervalued at work; fears losin...</td>\n",
       "      <td>fears losing job</td>\n",
       "      <td>The patient expresses fear of job loss, indica...</td>\n",
       "      <td>job insecurity</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2046</td>\n",
       "      <td>2</td>\n",
       "      <td>Patient is worried about losing his job due to...</td>\n",
       "      <td>worried about losing his job</td>\n",
       "      <td>Patient expresses fear of job loss due to heal...</td>\n",
       "      <td>job insecurity</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6082</td>\n",
       "      <td>3</td>\n",
       "      <td>The patient was attacked by a stranger on her ...</td>\n",
       "      <td>attacked by a stranger</td>\n",
       "      <td>The patient has been a victim of violence.</td>\n",
       "      <td>violence</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8862</td>\n",
       "      <td>4</td>\n",
       "      <td>He's been skipping meals to save up for his ki...</td>\n",
       "      <td>skipping meals || save up for his kid's tuition</td>\n",
       "      <td>Skipping meals can be a sign of food insecurit...</td>\n",
       "      <td>food insecurity || financial insecurity</td>\n",
       "      <td>yes || yes</td>\n",
       "      <td>current || current</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     idx  ex_no                                               Text  \\\n",
       "0  10742      0  He has suffered from chronic pain for several ...   \n",
       "1   8855      1  Patient feels undervalued at work; fears losin...   \n",
       "2   2046      2  Patient is worried about losing his job due to...   \n",
       "3   6082      3  The patient was attacked by a stranger on her ...   \n",
       "4   8862      4  He's been skipping meals to save up for his ki...   \n",
       "\n",
       "                                            Textspan  \\\n",
       "0  suffered from chronic pain || not addicted to ...   \n",
       "1                                   fears losing job   \n",
       "2                       worried about losing his job   \n",
       "3                             attacked by a stranger   \n",
       "4    skipping meals || save up for his kid's tuition   \n",
       "\n",
       "                                           Reasoning  \\\n",
       "0  The patient is suffering from chronic pain. ||...   \n",
       "1  The patient expresses fear of job loss, indica...   \n",
       "2  Patient expresses fear of job loss due to heal...   \n",
       "3         The patient has been a victim of violence.   \n",
       "4  Skipping meals can be a sign of food insecurit...   \n",
       "\n",
       "                                      SBDH    Presence              Period  \n",
       "0                  pain || substance abuse   yes || no  current || current  \n",
       "1                           job insecurity         yes             current  \n",
       "2                           job insecurity         yes             current  \n",
       "3                                 violence         yes             current  \n",
       "4  food insecurity || financial insecurity  yes || yes  current || current  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anns_df_collapsed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "psychological-plumbing",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'psychiatric symptoms or disorders': 1088, 'job insecurity': 1018, 'social isolation': 946, 'substance abuse': 842, 'financial insecurity': 817, 'housing insecurity': 696, 'loss of relationship': 664, 'pain': 625, 'transitions of care': 618, 'patient disability': 608, 'food insecurity': 519, 'violence': 502, 'barriers to care': 406, 'legal problems': 353, 'physical isolation': 320}) 10022\n",
      "Counter({'social isolation': 159, 'substance abuse': 139, 'psychiatric symptoms or disorders': 135, 'job insecurity': 126, 'loss of relationship': 103, 'housing insecurity': 101, 'financial insecurity': 101, 'pain': 100, 'transitions of care': 82, 'food insecurity': 79, 'patient disability': 79, 'violence': 77, 'barriers to care': 60, 'legal problems': 56, 'physical isolation': 46}) 1443\n",
      "{'psychiatric symptoms or disorders': 312, 'job insecurity': 303, 'social isolation': 281, 'substance abuse': 262, 'financial insecurity': 235, 'pain': 200, 'housing insecurity': 193, 'patient disability': 187, 'loss of relationship': 186, 'transitions of care': 153, 'violence': 151, 'food insecurity': 137, 'barriers to care': 111, 'legal problems': 109, 'physical isolation': 84, 'socioeconomic status': 1, 'education': 1}\n"
     ]
    }
   ],
   "source": [
    "# sbdh annotation distribution || train and val sets\n",
    "sbdh_list = []\n",
    "for sbdh in anns_df_collapsed.iloc[:num_train_examples]['SBDH'].tolist():\n",
    "    sbdh_list += sbdh.split(' || ')\n",
    "print(Counter(sbdh_list),len(sbdh_list))\n",
    "sbdh_list = []\n",
    "for sbdh in anns_df_collapsed.iloc[num_train_examples:num_train_examples+num_val_examples]['SBDH'].tolist():\n",
    "    sbdh_list += sbdh.split(' || ')\n",
    "print(Counter(sbdh_list),len(sbdh_list))\n",
    "sbdh_list = []\n",
    "# for sbdh in anns_df_collapsed.iloc[-num_test_examples:]['SBDH'].tolist():\n",
    "#     sbdh_list += sbdh.split(' || ')\n",
    "# print(Counter(sbdh_list),len(sbdh_list))\n",
    "\n",
    "# sbdh distribution || test set, before human correction, for table 11; we report correction stats on table 13\n",
    "raelene_ann = pd.read_csv('human_eval/synthetic_sbdh_annotation_raelene_adj_v2.csv',encoding='UTF-8')\n",
    "raelene_ann['exmpl_ann_no'] = raelene_ann.apply(lambda x:str(x['exmpl_no'])+'-'+str(x['ann_no']),axis=1)\n",
    "emily_ann = pd.read_csv('human_eval/synthetic_sbdh_annotation_emily_adj_v2.csv',encoding='UTF-8')\n",
    "emily_ann['exmpl_ann_no'] = emily_ann.apply(lambda x:str(x['exmpl_no'])+'-'+str(x['ann_no']),axis=1)\n",
    "df = pd.concat([\n",
    "    emily_ann.copy(),\n",
    "    raelene_ann[raelene_ann['exmpl_no']>=1000].copy()\n",
    "], ignore_index=True, sort=False)\n",
    "df['SBDH'] = df['SBDH'].apply(lambda x: x.lower())\n",
    "print(df[df['Annotator']=='GPT-4']['SBDH'].value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de74fd53-e37c-4adf-97ad-bc91a0120da5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "job insecurity >>>> {'yes': 993, 'no': 25} {'current': 959, 'history': 59}\n",
      "substance abuse >>>> {'yes': 717, 'no': 125} {'current': 581, 'history': 261}\n",
      "social isolation >>>> {'yes': 923, 'no': 23} {'current': 942, 'history': 4}\n",
      "psychiatric symptoms or disorders >>>> {'yes': 1082, 'no': 6} {'current': 1026, 'history': 62}\n",
      "housing insecurity >>>> {'yes': 663, 'no': 33} {'current': 632, 'history': 64}\n",
      "financial insecurity >>>> {'yes': 801, 'no': 16} {'current': 802, 'history': 15}\n",
      "patient disability >>>> {'yes': 603, 'no': 5} {'current': 591, 'history': 17}\n",
      "pain >>>> {'yes': 624, 'no': 1} {'current': 612, 'history': 13}\n",
      "loss of relationship >>>> {'yes': 660, 'no': 4} {'current': 453, 'history': 211}\n",
      "transitions of care >>>> {'yes': 613, 'no': 5} {'current': 559, 'history': 59}\n",
      "food insecurity >>>> {'yes': 504, 'no': 15} {'current': 514, 'history': 5}\n",
      "violence >>>> {'yes': 494, 'no': 8} {'history': 253, 'current': 249}\n",
      "barriers to care >>>> {'yes': 387, 'no': 19} {'current': 404, 'history': 2}\n",
      "legal problems >>>> {'yes': 345, 'no': 8} {'current': 283, 'history': 70}\n",
      "physical isolation >>>> {'yes': 318, 'no': 2} {'current': 320}\n",
      "--------------------------------------------------\n",
      "job insecurity >>>> {'yes': 124, 'no': 2} {'current': 121, 'history': 5}\n",
      "substance abuse >>>> {'yes': 109, 'no': 30} {'current': 92, 'history': 47}\n",
      "social isolation >>>> {'yes': 158, 'no': 1} {'current': 157, 'history': 2}\n",
      "psychiatric symptoms or disorders >>>> {'yes': 134, 'no': 1} {'current': 126, 'history': 9}\n",
      "housing insecurity >>>> {'yes': 100, 'no': 1} {'current': 88, 'history': 13}\n",
      "financial insecurity >>>> {'yes': 100, 'no': 1} {'current': 97, 'history': 4}\n",
      "patient disability >>>> {'yes': 79} {'current': 76, 'history': 3}\n",
      "pain >>>> {'yes': 98, 'no': 2} {'current': 96, 'history': 4}\n",
      "loss of relationship >>>> {'yes': 103} {'current': 64, 'history': 39}\n",
      "transitions of care >>>> {'yes': 82} {'current': 75, 'history': 7}\n",
      "food insecurity >>>> {'yes': 72, 'no': 7} {'current': 78, 'history': 1}\n",
      "violence >>>> {'yes': 76, 'no': 1} {'current': 43, 'history': 34}\n",
      "barriers to care >>>> {'yes': 54, 'no': 6} {'current': 60}\n",
      "legal problems >>>> {'yes': 55, 'no': 1} {'current': 43, 'history': 13}\n",
      "physical isolation >>>> {'yes': 46} {'current': 46}\n",
      "--------------------------------------------------\n",
      "job insecurity >>>> {'yes': 298, 'no': 5} {'current': 290, 'history': 13}\n",
      "substance abuse >>>> {'yes': 226, 'no': 36} {'current': 189, 'history': 73}\n",
      "social isolation >>>> {'yes': 275, 'no': 6} {'current': 281}\n",
      "psychiatric symptoms or disorders >>>> {'yes': 312} {'current': 299, 'history': 13}\n",
      "housing insecurity >>>> {'yes': 182, 'no': 11} {'current': 175, 'history': 18}\n",
      "financial insecurity >>>> {'yes': 233, 'no': 2} {'current': 226, 'history': 9}\n",
      "patient disability >>>> {'yes': 185, 'no': 2} {'current': 180, 'history': 6, 'unclear': 1}\n",
      "pain >>>> {'yes': 199, 'no': 1} {'current': 192, 'history': 8}\n",
      "loss of relationship >>>> {'yes': 185, 'no': 1} {'current': 132, 'history': 54}\n",
      "transitions of care >>>> {'yes': 152, 'no': 1} {'current': 141, 'history': 12}\n",
      "food insecurity >>>> {'yes': 136, 'no': 1} {'current': 135, 'history': 2}\n",
      "violence >>>> {'yes': 148, 'no': 3} {'current': 83, 'history': 68}\n",
      "barriers to care >>>> {'yes': 106, 'no': 5} {'current': 110, 'history': 1}\n",
      "legal problems >>>> {'yes': 107, 'no': 2} {'current': 88, 'history': 21}\n",
      "physical isolation >>>> {'yes': 84} {'current': 83, 'history': 1}\n"
     ]
    }
   ],
   "source": [
    "for sbdh in sbdh_types:\n",
    "    tr_ids = anns_df['idx'].unique().tolist()[:num_train_examples]\n",
    "    print(\n",
    "        sbdh, '>>>>',\n",
    "        dict(anns_df[(anns_df['idx'].isin(tr_ids))&(anns_df['SBDH']==sbdh)]['Presence'].value_counts()), \n",
    "        dict(anns_df[(anns_df['idx'].isin(tr_ids))&(anns_df['SBDH']==sbdh)]['Period'].value_counts()))\n",
    "print('-'*50)\n",
    "for sbdh in sbdh_types:\n",
    "    val_ids = anns_df['idx'].unique().tolist()[num_train_examples:num_train_examples+num_val_examples]\n",
    "    print(\n",
    "        sbdh, '>>>>',\n",
    "        dict(anns_df[(anns_df['idx'].isin(val_ids))&(anns_df['SBDH']==sbdh)]['Presence'].value_counts()), \n",
    "        dict(anns_df[(anns_df['idx'].isin(val_ids))&(anns_df['SBDH']==sbdh)]['Period'].value_counts()))\n",
    "print('-'*50)\n",
    "for sbdh in sbdh_types:\n",
    "    print(\n",
    "        sbdh, '>>>>',\n",
    "        dict(df[(df['Annotator']=='GPT-4')&(df['SBDH']==sbdh)]['Presence'].value_counts()), \n",
    "        dict(df[(df['Annotator']=='GPT-4')&(df['SBDH']==sbdh)]['Period'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3c22ec9-6679-422d-a71a-68e1b28a1caf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_barriers_to_care                      375\n",
       "label_substance_abuse                       624\n",
       "label_housing_insecurity                    602\n",
       "label_patient_disability                    567\n",
       "label_legal_problems                        315\n",
       "label_food_insecurity                       488\n",
       "label_transitions_of_care                   566\n",
       "label_psychiatric_symptoms_or_disorders    1010\n",
       "label_isolation_or_loss_of_relationship    1430\n",
       "label_violence                              467\n",
       "label_pain                                  615\n",
       "label_financial_insecurity                 1437\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label_barriers_to_care                      51\n",
       "label_substance_abuse                       90\n",
       "label_housing_insecurity                    88\n",
       "label_patient_disability                    76\n",
       "label_legal_problems                        47\n",
       "label_food_insecurity                       69\n",
       "label_transitions_of_care                   73\n",
       "label_psychiatric_symptoms_or_disorders    127\n",
       "label_isolation_or_loss_of_relationship    228\n",
       "label_violence                              73\n",
       "label_pain                                  94\n",
       "label_financial_insecurity                 190\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label_barriers_to_care                     100\n",
       "label_substance_abuse                      195\n",
       "label_housing_insecurity                   167\n",
       "label_patient_disability                   169\n",
       "label_legal_problems                       102\n",
       "label_food_insecurity                      131\n",
       "label_transitions_of_care                  138\n",
       "label_psychiatric_symptoms_or_disorders    278\n",
       "label_isolation_or_loss_of_relationship    406\n",
       "label_violence                             139\n",
       "label_pain                                 190\n",
       "label_financial_insecurity                 424\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sbdh classification label distribution\n",
    "with open('synth_data_gpt4/sbdh_gpt4_v3_multilabel_train.json') as f:\n",
    "    display(pd.DataFrame(json.load(f)['data']).iloc[:,1:-2].sum(axis=0))\n",
    "print('-'*50)\n",
    "with open('synth_data_gpt4/sbdh_gpt4_v3_multilabel_valid.json') as f:\n",
    "    display(pd.DataFrame(json.load(f)['data']).iloc[:,1:-2].sum(axis=0))\n",
    "print('-'*50)\n",
    "with open('synth_data_gpt4/sbdh_gpt4_v3_multilabel_test.json') as f:\n",
    "    display(pd.DataFrame(json.load(f)['data']).iloc[:,1:-2].sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7735b927-89fe-45cb-9711-ae836ad289ea",
   "metadata": {},
   "source": [
    "### Finalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ddbff51-c748-4502-ba54-f33786883b62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cols = ['ex_no', 'Text', 'Textspan', 'SBDH', 'Presence', 'Period', 'Reasoning']\n",
    "anns_df_collapsed.iloc[:num_train_examples][cols].to_csv('synth_sbdh/synth_sbdh_train.csv',index=False)\n",
    "anns_df_collapsed.iloc[num_train_examples:num_train_examples+num_val_examples][cols].to_csv('synth_sbdh/synth_sbdh_val.csv',index=False)\n",
    "anns_df_collapsed.iloc[-num_test_examples:][cols].to_csv('synth_sbdh/synth_sbdh_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5189391e-cb26-41b1-837e-03d14c1c8062",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf4da9fac1d43168d483c0deaab975b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1732 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ex_no</th>\n",
       "      <th>Text</th>\n",
       "      <th>Textspan</th>\n",
       "      <th>Reasoning</th>\n",
       "      <th>SBDH</th>\n",
       "      <th>Presence</th>\n",
       "      <th>Period</th>\n",
       "      <th>Operation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7012</td>\n",
       "      <td>His lower back pain has been worsening over th...</td>\n",
       "      <td>lower back pain</td>\n",
       "      <td>experiencing lower back pain is a sign of the ...</td>\n",
       "      <td>pain</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7013</td>\n",
       "      <td>The patient has recently been laid off from hi...</td>\n",
       "      <td>recently been laid off || concern about his fi...</td>\n",
       "      <td>the patient lost his job recently, indicating ...</td>\n",
       "      <td>job insecurity || financial insecurity</td>\n",
       "      <td>yes || yes</td>\n",
       "      <td>current || current</td>\n",
       "      <td>keep || keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7014</td>\n",
       "      <td>Patient finds it difficult to travel to the cl...</td>\n",
       "      <td>difficult to travel to the clinic || lack of t...</td>\n",
       "      <td>difficulty in traveling to the clinic due to l...</td>\n",
       "      <td>barriers to care || barriers to care</td>\n",
       "      <td>yes || yes</td>\n",
       "      <td>current || current</td>\n",
       "      <td>keep || add</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7015</td>\n",
       "      <td>Veteran is going through a divorce and his wif...</td>\n",
       "      <td>going through a divorce || wife moved out</td>\n",
       "      <td>divorce is considered a loss of a personal rel...</td>\n",
       "      <td>loss of relationship || loss of relationship</td>\n",
       "      <td>yes || yes</td>\n",
       "      <td>current || current</td>\n",
       "      <td>keep || add</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7016</td>\n",
       "      <td>Patient suffers from anxiety and has been havi...</td>\n",
       "      <td>suffers from anxiety || frequent panic attacks</td>\n",
       "      <td>the patient has a psychiatric disorder - anxie...</td>\n",
       "      <td>psychiatric symptoms or disorders || psychiatr...</td>\n",
       "      <td>yes || yes</td>\n",
       "      <td>current || current</td>\n",
       "      <td>keep || keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>8762</td>\n",
       "      <td>He was arrested for DUI last month and is now ...</td>\n",
       "      <td>arrested for dui || facing legal proceedings</td>\n",
       "      <td>arrest for a dui indicates a violation of law ...</td>\n",
       "      <td>legal problems || legal problems</td>\n",
       "      <td>yes || yes</td>\n",
       "      <td>current || current</td>\n",
       "      <td>keep || add</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>8763</td>\n",
       "      <td>Patient has been living alone for the past few...</td>\n",
       "      <td>living alone || rarely goes out</td>\n",
       "      <td>living alone often leads to social isolation. ...</td>\n",
       "      <td>social isolation || social isolation</td>\n",
       "      <td>yes || yes</td>\n",
       "      <td>current || current</td>\n",
       "      <td>keep || correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>8764</td>\n",
       "      <td>The patient, who is wheelchair-bound, requires...</td>\n",
       "      <td>wheelchair-bound</td>\n",
       "      <td>being wheelchair-bound indicates a physical di...</td>\n",
       "      <td>patient disability</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>8765</td>\n",
       "      <td>Patient has had frequent hospital admissions d...</td>\n",
       "      <td>frequent hospital admissions</td>\n",
       "      <td>frequent hospital admissions indicate transiti...</td>\n",
       "      <td>transitions of care</td>\n",
       "      <td>yes</td>\n",
       "      <td>unclear</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>8766</td>\n",
       "      <td>Reports issues with chronic pain that has dist...</td>\n",
       "      <td>chronic pain || disturbed his sleep</td>\n",
       "      <td>the mention of chronic pain indicates that the...</td>\n",
       "      <td>pain || psychiatric symptoms or disorders</td>\n",
       "      <td>yes || yes</td>\n",
       "      <td>current || current</td>\n",
       "      <td>keep || add</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1732 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ex_no                                               Text  \\\n",
       "0      7012  His lower back pain has been worsening over th...   \n",
       "1      7013  The patient has recently been laid off from hi...   \n",
       "2      7014  Patient finds it difficult to travel to the cl...   \n",
       "3      7015  Veteran is going through a divorce and his wif...   \n",
       "4      7016  Patient suffers from anxiety and has been havi...   \n",
       "...     ...                                                ...   \n",
       "1727   8762  He was arrested for DUI last month and is now ...   \n",
       "1728   8763  Patient has been living alone for the past few...   \n",
       "1729   8764  The patient, who is wheelchair-bound, requires...   \n",
       "1730   8765  Patient has had frequent hospital admissions d...   \n",
       "1731   8766  Reports issues with chronic pain that has dist...   \n",
       "\n",
       "                                               Textspan  \\\n",
       "0                                       lower back pain   \n",
       "1     recently been laid off || concern about his fi...   \n",
       "2     difficult to travel to the clinic || lack of t...   \n",
       "3             going through a divorce || wife moved out   \n",
       "4        suffers from anxiety || frequent panic attacks   \n",
       "...                                                 ...   \n",
       "1727       arrested for dui || facing legal proceedings   \n",
       "1728                    living alone || rarely goes out   \n",
       "1729                                   wheelchair-bound   \n",
       "1730                       frequent hospital admissions   \n",
       "1731                chronic pain || disturbed his sleep   \n",
       "\n",
       "                                              Reasoning  \\\n",
       "0     experiencing lower back pain is a sign of the ...   \n",
       "1     the patient lost his job recently, indicating ...   \n",
       "2     difficulty in traveling to the clinic due to l...   \n",
       "3     divorce is considered a loss of a personal rel...   \n",
       "4     the patient has a psychiatric disorder - anxie...   \n",
       "...                                                 ...   \n",
       "1727  arrest for a dui indicates a violation of law ...   \n",
       "1728  living alone often leads to social isolation. ...   \n",
       "1729  being wheelchair-bound indicates a physical di...   \n",
       "1730  frequent hospital admissions indicate transiti...   \n",
       "1731  the mention of chronic pain indicates that the...   \n",
       "\n",
       "                                                   SBDH    Presence  \\\n",
       "0                                                  pain         yes   \n",
       "1                job insecurity || financial insecurity  yes || yes   \n",
       "2                  barriers to care || barriers to care  yes || yes   \n",
       "3          loss of relationship || loss of relationship  yes || yes   \n",
       "4     psychiatric symptoms or disorders || psychiatr...  yes || yes   \n",
       "...                                                 ...         ...   \n",
       "1727                   legal problems || legal problems  yes || yes   \n",
       "1728               social isolation || social isolation  yes || yes   \n",
       "1729                                 patient disability         yes   \n",
       "1730                                transitions of care         yes   \n",
       "1731          pain || psychiatric symptoms or disorders  yes || yes   \n",
       "\n",
       "                  Period        Operation  \n",
       "0                current             keep  \n",
       "1     current || current     keep || keep  \n",
       "2     current || current      keep || add  \n",
       "3     current || current      keep || add  \n",
       "4     current || current     keep || keep  \n",
       "...                  ...              ...  \n",
       "1727  current || current      keep || add  \n",
       "1728  current || current  keep || correct  \n",
       "1729             current             keep  \n",
       "1730             unclear          correct  \n",
       "1731  current || current      keep || add  \n",
       "\n",
       "[1732 rows x 8 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('human_eval/sbdh_gpt4_v3_test_cmbd_consolidated.csv')\n",
    "df['ex_no'] = df['ex_no'].apply(lambda x:x+7012)\n",
    "df = df[df['Operation']!='discard'][cols+['Operation']].copy()\n",
    "\n",
    "anns_df_collapsed = pd.DataFrame(df['ex_no'].unique(),columns=['ex_no']).copy()\n",
    "for col in ['Text', 'Textspan', 'Reasoning', 'SBDH', 'Presence', 'Period', 'Operation']: \n",
    "    anns_df_collapsed[col] = 0\n",
    "    \n",
    "for i,idx in tqdm(enumerate(df['ex_no'].unique()),total=anns_df_collapsed.shape[0]):\n",
    "    temp_df = df[df['ex_no']==idx].copy()\n",
    "    assert temp_df['Text'].nunique()==1\n",
    "    for col in ['Textspan', 'Reasoning', 'SBDH', 'Presence', 'Period', 'Operation']:\n",
    "        assert 'XXX' not in temp_df[col].tolist()\n",
    "        anns_df_collapsed.loc[i,col] = ' || '.join(map(str.lower,temp_df[col].tolist()))\n",
    "    anns_df_collapsed.loc[i,'Text'] = temp_df.iloc[0]['Text']\n",
    "\n",
    "anns_df_collapsed = pd.DataFrame(anns_df_collapsed)\n",
    "anns_df_collapsed.to_csv('synth_sbdh/synth_sbdh_test_reviewed.csv',index=False)\n",
    "anns_df_collapsed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61dcbbe8-b716-4ebd-aa97-6630ca5f3202",
   "metadata": {},
   "source": [
    "### Convert to BIO format (Presence=Yes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "b936a681-036c-453a-a07a-ac8cbd6c03d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"eligible_idxs.json\") as fp:\n",
    "    eligible_idxs = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 851,
   "id": "dab98ddb-e350-4160-8345-87c60e1e1df9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b528c62a1a8c47fd89036fd5eb7257e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8767 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def find_sub_list(sl,l):\n",
    "    results=[]\n",
    "    sll=len(sl)\n",
    "    for ind in (i for i,e in enumerate(l) if e==sl[0]):\n",
    "        if l[ind:ind+sll]==sl:\n",
    "            results.append((ind,ind+sll))\n",
    "\n",
    "    return results\n",
    "\n",
    "bio_formatted_data = []\n",
    "for row_id in tqdm(range(anns_df_collapsed.loc[eligible_idxs].shape[0])):\n",
    "    temp_dict = {}\n",
    "    text = word_tokenize(anns_df_collapsed.loc[eligible_idxs].iloc[row_id]['Text'])\n",
    "    temp_dict['tokens'] = text\n",
    "    text_sbdh_tags = ['O']*len(text)\n",
    "    # text_presence_tags = ['O']*len(text)\n",
    "    text_period_tags = ['O']*len(text)\n",
    "\n",
    "    sbdh_tags = [sbdh_map_dict[i].replace(' ','_') for i in anns_df_collapsed.loc[eligible_idxs].iloc[row_id]['SBDH'].split(' || ')]\n",
    "    presence_tags = anns_df_collapsed.loc[eligible_idxs].iloc[row_id]['Presence'].split(' || ')\n",
    "    period_tags = anns_df_collapsed.loc[eligible_idxs].iloc[row_id]['Period'].split(' || ')\n",
    "    \n",
    "    all_sl_idxs = []\n",
    "    for i,span in enumerate(anns_df_collapsed.loc[eligible_idxs].iloc[row_id]['Textspan'].split(' || ')):\n",
    "        if presence_tags[i] == 'yes': # only consider presence=yes\n",
    "            textspan = word_tokenize(span)\n",
    "            sl_idxs = find_sub_list(textspan,text) \n",
    "            for idx in sl_idxs:\n",
    "                if text_sbdh_tags[idx[0]:idx[1]] == ['O']*len(textspan): # only put labels if the tokens are already unlabeled; avoiding nested labels\n",
    "                    text_sbdh_tags[idx[0]] = 'B-'+sbdh_tags[i]\n",
    "                    text_sbdh_tags[idx[0]+1:idx[1]] = ['I-'+sbdh_tags[i]]*(len(textspan)-1)\n",
    "                    # text_presence_tags[idx[0]] = 'B-'+presence_tags[i]\n",
    "                    # text_presence_tags[idx[0]+1:idx[1]] = ['I-'+presence_tags[i]]*(len(textspan)-1)\n",
    "                    text_period_tags[idx[0]] = 'B-'+period_tags[i]\n",
    "                    text_period_tags[idx[0]+1:idx[1]] = ['I-'+period_tags[i]]*(len(textspan)-1)\n",
    "                    all_sl_idxs += [idx]\n",
    "    \n",
    "    if len(all_sl_idxs)>1:\n",
    "        for idx1, idx2 in zip(all_sl_idxs[:-1],all_sl_idxs[1:]):\n",
    "            if set(range(*idx1)).intersection(set(range(*idx2))): \n",
    "                print(f'Testspan overlap found at {row_id}!')\n",
    "                break\n",
    "            \n",
    "    # print(text)\n",
    "    temp_dict['ner_tags'] = text_sbdh_tags\n",
    "    # temp_dict['presence_tags'] = text_presence_tags\n",
    "    temp_dict['period_tags'] = text_period_tags\n",
    "    bio_formatted_data += [temp_dict]\n",
    "\n",
    "# bio_formatted_data = {'data':bio_formatted_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "id": "42937014-97ad-4258-bcdd-a0d7c7e0e2aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tokens': ['Patient', 'feels', 'undervalued', 'at', 'work', ';', 'fears', 'losing', 'job', 'due', 'to', 'company', 'downsizing', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'B-financial_insecurity', 'I-financial_insecurity', 'I-financial_insecurity', 'O', 'O', 'O', 'O', 'O'], 'period_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'B-current', 'I-current', 'I-current', 'O', 'O', 'O', 'O', 'O']}\n"
     ]
    }
   ],
   "source": [
    "print(bio_formatted_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 852,
   "id": "ea4f03d3-4d66-4eba-a97f-1fb7efbbbaeb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6136 876 1755\n"
     ]
    }
   ],
   "source": [
    "num_train_examples = int(len(bio_formatted_data)*.7)\n",
    "num_val_examples = int(len(bio_formatted_data)*.1)\n",
    "num_test_examples = len(bio_formatted_data) - num_train_examples - num_val_examples\n",
    "print(num_train_examples, num_val_examples, num_test_examples)\n",
    "\n",
    "random.seed(0)\n",
    "random.shuffle(bio_formatted_data)\n",
    "with open('synth_data_gpt4/synth_data_aio_BIO_train_v2.json','w') as f:\n",
    "    json.dump({'data':bio_formatted_data[:num_train_examples]}, f)\n",
    "with open('synth_data_gpt4/synth_data_aio_BIO_val_v2.json','w') as f:\n",
    "    json.dump({'data':bio_formatted_data[num_train_examples:num_train_examples+num_val_examples]}, f)\n",
    "with open('synth_data_gpt4/synth_data_aio_BIO_test_v2.json','w') as f:\n",
    "    json.dump({'data':bio_formatted_data[-num_test_examples:]}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbed02d3-68a1-4be9-9dca-012a58db4671",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge train and test sets\n",
    "with open('synth_data_gpt4/synth_data_aio_BIO_train_v2.json') as f:\n",
    "    a = json.load(f)['data']\n",
    "# with open('synth_data_gpt4/synth_data_aio_BIO_test_v2.json') as f:\n",
    "#     b = json.load(f)['data']\n",
    "with open('synth_data_gpt4/synth_data_aio_BIO_test_hr_v2.json') as f:\n",
    "    b = json.load(f)['data']\n",
    "with open('synth_data_gpt4/synth_data_aio_BIO_train&test_hr_v2.json','w') as f:\n",
    "    json.dump({'data':a+b}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd74f000-316f-45f6-bfd0-6f38bc3d0429",
   "metadata": {},
   "source": [
    "### Convert to BIO format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "69901649-1e7e-4409-a252-0f26cc92bb6b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aff8c163f6b84fa08ddee0ebb94abc0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8767 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def find_sub_list(sl,l):\n",
    "    results=[]\n",
    "    sll=len(sl)\n",
    "    for ind in (i for i,e in enumerate(l) if e==sl[0]):\n",
    "        if l[ind:ind+sll]==sl:\n",
    "            results.append((ind,ind+sll))\n",
    "\n",
    "    return results\n",
    "\n",
    "bio_formatted_data = []\n",
    "for row_id in tqdm(range(anns_df_collapsed.loc[eligible_idxs].shape[0])):\n",
    "    temp_dict = {}\n",
    "    text = word_tokenize(anns_df_collapsed.loc[eligible_idxs].iloc[row_id]['Text'])\n",
    "    temp_dict['tokens'] = text\n",
    "    text_sbdh_tags = ['O']*len(text)\n",
    "    text_presence_tags = ['O']*len(text)\n",
    "    text_period_tags = ['O']*len(text)\n",
    "\n",
    "    sbdh_tags = [sbdh_map_dict[i].replace(' ','_') for i in anns_df_collapsed.loc[eligible_idxs].iloc[row_id]['SBDH'].split(' || ')]\n",
    "    presence_tags = anns_df_collapsed.loc[eligible_idxs].iloc[row_id]['Presence'].split(' || ')\n",
    "    period_tags = anns_df_collapsed.loc[eligible_idxs].iloc[row_id]['Period'].split(' || ')\n",
    "    \n",
    "    all_sl_idxs = []\n",
    "    for i,span in enumerate(anns_df_collapsed.loc[eligible_idxs].iloc[row_id]['Textspan'].split(' || ')):\n",
    "        textspan = word_tokenize(span)\n",
    "        sl_idxs = find_sub_list(textspan,text) \n",
    "        for idx in sl_idxs:\n",
    "            if text_sbdh_tags[idx[0]:idx[1]] == ['O']*len(textspan): # only put labels if the tokens are already unlabeled; avoiding nested labels\n",
    "                text_sbdh_tags[idx[0]] = 'B-'+sbdh_tags[i]\n",
    "                text_sbdh_tags[idx[0]+1:idx[1]] = ['I-'+sbdh_tags[i]]*(len(textspan)-1)\n",
    "                text_presence_tags[idx[0]] = 'B-'+presence_tags[i]\n",
    "                text_presence_tags[idx[0]+1:idx[1]] = ['I-'+presence_tags[i]]*(len(textspan)-1)\n",
    "                text_period_tags[idx[0]] = 'B-'+period_tags[i]\n",
    "                text_period_tags[idx[0]+1:idx[1]] = ['I-'+period_tags[i]]*(len(textspan)-1)\n",
    "                all_sl_idxs += [idx]\n",
    "    \n",
    "    if len(all_sl_idxs)>1:\n",
    "        for idx1, idx2 in zip(all_sl_idxs[:-1],all_sl_idxs[1:]):\n",
    "            if set(range(*idx1)).intersection(set(range(*idx2))): \n",
    "                print(f'Testspan overlap found at {row_id}!')\n",
    "                break\n",
    "            \n",
    "    # print(text)\n",
    "    temp_dict['ner_tags'] = text_sbdh_tags\n",
    "    temp_dict['presence_tags'] = text_presence_tags\n",
    "    temp_dict['period_tags'] = text_period_tags\n",
    "    bio_formatted_data += [temp_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "47b8a974-3347-40bd-9d52-e4230cff08da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6136 876 1755\n"
     ]
    }
   ],
   "source": [
    "num_train_examples = int(len(bio_formatted_data)*.7)\n",
    "num_val_examples = int(len(bio_formatted_data)*.1)\n",
    "num_test_examples = len(bio_formatted_data) - num_train_examples - num_val_examples\n",
    "print(num_train_examples, num_val_examples, num_test_examples)\n",
    "\n",
    "random.seed(0)\n",
    "random.shuffle(bio_formatted_data)\n",
    "with open('synth_data_gpt4/synth_data_aio_BIO_wPresence_train_v3.json','w') as f:\n",
    "    json.dump({'data':bio_formatted_data[:num_train_examples]}, f)\n",
    "with open('synth_data_gpt4/synth_data_aio_BIO_wPresence_val_v3.json','w') as f:\n",
    "    json.dump({'data':bio_formatted_data[num_train_examples:num_train_examples+num_val_examples]}, f)\n",
    "with open('synth_data_gpt4/synth_data_aio_BIO_wPresence_test_v3.json','w') as f:\n",
    "    json.dump({'data':bio_formatted_data[-num_test_examples:]}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f757139a-13a1-40d0-836d-a8e7dfdaeeae",
   "metadata": {},
   "source": [
    "### Convert to DSS format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "9c7a790f-b023-4479-b46d-6c36ab53a03e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0244fa0576524d8cbc7135ba3ee93afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8767 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped annotations: 99, out of 14342\n"
     ]
    }
   ],
   "source": [
    "def is_nested(range1list:list, range2list:list, verbose=False):\n",
    "    '''\n",
    "    Find if there is an intersection between elements in range1list and range2list.\n",
    "    '''\n",
    "    if len(range1list)==0 or len(range2list)==0: return False\n",
    "    for range2 in range2list:\n",
    "        for range1 in range1list:\n",
    "            if set(range(*range1)).intersection(set(range(*range2))):\n",
    "                if verbose:print(range1,range2)\n",
    "                return True\n",
    "    return False\n",
    "        \n",
    "formatted_data = []\n",
    "skip_count, total_ann_count = 0, 0\n",
    "for row_id in tqdm(range(anns_df_collapsed.loc[eligible_idxs].shape[0])):\n",
    "    temp_dict = {}\n",
    "    temp_dict['text'] = anns_df_collapsed.loc[eligible_idxs].iloc[row_id]['Text']\n",
    "\n",
    "    sbdh_tags = [sbdh_map_dict[i].replace(' ','_') for i in anns_df_collapsed.loc[eligible_idxs].iloc[row_id]['SBDH'].split(' || ')]\n",
    "    presence_tags = [i for i in anns_df_collapsed.loc[eligible_idxs].iloc[row_id]['Presence'].split(' || ')]\n",
    "    period_tags = [i for i in anns_df_collapsed.loc[eligible_idxs].iloc[row_id]['Period'].split(' || ')]\n",
    "    reasoning_tags = [i for i in anns_df_collapsed.loc[eligible_idxs].iloc[row_id]['Reasoning'].split(' || ')]\n",
    "    # temp_dict['reasoning'] = anns_df_collapsed.loc[eligible_idxs].iloc[row_id]['Reasoning'].replace(' || ',' ')\n",
    "    sbdh_ann, period_ann, reasoning_ann = [], [], []\n",
    "    \n",
    "    textspan_indices = []\n",
    "    for i,textspan in enumerate(anns_df_collapsed.loc[eligible_idxs].iloc[row_id]['Textspan'].split(' || ')):\n",
    "        total_ann_count += 1\n",
    "        if presence_tags[i] == 'yes': # only consider presence=yes\n",
    "            sl_indices = find_sub_list(textspan,temp_dict['text'])\n",
    "            if is_nested(textspan_indices,sl_indices): # check for nested annotations and skip if found any\n",
    "                skip_count += 1\n",
    "                continue \n",
    "            textspan_indices += sl_indices\n",
    "            sbdh_ann += [textspan+' <'+sbdh_tags[i]+'>']\n",
    "            period_ann += [textspan+' <'+period_tags[i]+'>']\n",
    "            reasoning_ann += [reasoning_tags[i]]\n",
    "    temp_dict['sbdh_ann'] = ', '.join(sbdh_ann)\n",
    "    temp_dict['period_ann'] = ', '.join(period_ann)\n",
    "    temp_dict['reasoning'] = ' '.join(reasoning_ann)\n",
    "    formatted_data += [temp_dict]\n",
    "    # if row_id==10: break\n",
    "print(f'Skipped annotations: {skip_count}, out of {total_ann_count}')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "fa4770db-ce9a-4445-8187-b9b331b2e439",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6136 876 1755\n"
     ]
    }
   ],
   "source": [
    "# v3: corrected 'reasoning' field, v2 has erroneous (nested/presece=No) reasonings\n",
    "num_train_examples = int(len(formatted_data)*.7)\n",
    "num_val_examples = int(len(formatted_data)*.1)\n",
    "num_test_examples = len(formatted_data) - num_train_examples - num_val_examples\n",
    "print(num_train_examples, num_val_examples, num_test_examples)\n",
    "\n",
    "random.seed(0)\n",
    "random.shuffle(formatted_data)\n",
    "with open('synth_data_gpt4/sbdh_gpt4_v3_train.json','w') as f:\n",
    "    json.dump({'data':formatted_data[:num_train_examples]}, f)\n",
    "with open('synth_data_gpt4/sbdh_gpt4_v3_valid.json','w') as f:\n",
    "    json.dump({'data':formatted_data[num_train_examples:num_train_examples+num_val_examples]}, f)\n",
    "with open('synth_data_gpt4/sbdh_gpt4_v3_test.json','w') as f:\n",
    "    json.dump({'data':formatted_data[-num_test_examples:]}, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de4c54f-9dfb-4791-9b72-2aef263e314e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Convert to MLC format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2321f078-b938-408c-94f1-6e7edc23b05c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"eligible_idxs.json\") as fp:\n",
    "    eligible_idxs = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "705c8eb0-e4d4-4df5-9478-6d798c125818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be78676f40c0443ca99b07adf18da768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8767 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total annotations: 14342\n"
     ]
    }
   ],
   "source": [
    "formatted_data = []\n",
    "total_ann_count = 0\n",
    "for row_id in tqdm(range(anns_df_collapsed.loc[eligible_idxs].shape[0])):\n",
    "    temp_dict = {}\n",
    "    temp_dict['text'] = anns_df_collapsed.loc[eligible_idxs].iloc[row_id]['Text']\n",
    "\n",
    "    sbdh_tags = [sbdh_map_dict[i].replace(' ','_') for i in anns_df_collapsed.loc[eligible_idxs].iloc[row_id]['SBDH'].split(' || ')]\n",
    "    presence_tags = anns_df_collapsed.loc[eligible_idxs].iloc[row_id]['Presence'].split(' || ')\n",
    "    # temp_dict['reasoning'] = anns_df_collapsed.loc[eligible_idxs].iloc[row_id]['Reasoning'].replace(' || ',' ')\n",
    "    reasoning_tags = anns_df_collapsed.loc[eligible_idxs].iloc[row_id]['Reasoning'].split(' || ')\n",
    "    \n",
    "    for sbdh in set(sbdh_map_dict.values()):\n",
    "        temp_dict['label_'+sbdh.replace(' ','_')] = 0\n",
    "    \n",
    "    sbdh_ann, reasoning_ann, textspan_indices = [], [], []\n",
    "    for i,_ in enumerate(presence_tags):\n",
    "        total_ann_count += 1\n",
    "        if presence_tags[i] == 'yes': # only consider presence=yes\n",
    "            temp_dict['label_'+sbdh_tags[i]] = 1\n",
    "            sbdh_ann += ['<'+sbdh_tags[i]+'>']\n",
    "            reasoning_ann += [reasoning_tags[i]]\n",
    "    temp_dict['sbdh_ann'] = ', '.join(set(sbdh_ann))\n",
    "    temp_dict['reasoning'] = ' '.join(reasoning_ann)\n",
    "    formatted_data += [temp_dict]\n",
    "print(f'Total annotations: {total_ann_count}')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eb12ad3e-865c-406d-8ae5-bf09d3330bc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'His wife reports that he has been avoiding alcohol and drugs since his rehab.',\n",
       " 'reasoning': \"The patient's avoidance of alcohol and drugs post-rehab indicates an absence of substance abuse.\",\n",
       " 'label_barriers_to_care': 0,\n",
       " 'label_substance_abuse': 0,\n",
       " 'label_housing_insecurity': 0,\n",
       " 'label_patient_disability': 0,\n",
       " 'label_legal_problems': 0,\n",
       " 'label_food_insecurity': 0,\n",
       " 'label_transitions_of_care': 0,\n",
       " 'label_psychiatric_symptoms_or_disorders': 0,\n",
       " 'label_isolation_or_loss_of_relationship': 0,\n",
       " 'label_violence': 0,\n",
       " 'label_pain': 0,\n",
       " 'label_financial_insecurity': 0,\n",
       " 'sbdh_ann': ''}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_data[1331]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ffab511-e9a0-445e-acde-eca622cf5fe9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_barriers_to_care                                                                   526\n",
       "label_substance_abuse                                                                    909\n",
       "label_housing_insecurity                                                                 857\n",
       "label_patient_disability                                                                 812\n",
       "label_legal_problems                                                                     464\n",
       "label_food_insecurity                                                                    688\n",
       "label_transitions_of_care                                                                777\n",
       "label_psychiatric_symptoms_or_disorders                                                 1415\n",
       "label_isolation_or_loss_of_relationship                                                 2064\n",
       "label_violence                                                                           679\n",
       "label_pain                                                                               899\n",
       "label_financial_insecurity                                                              2051\n",
       "sbdh_ann                                   <isolation_or_loss_of_relationship>, <psychiat...\n",
       "dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(formatted_data).iloc[:,2:].sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "51898a33-8210-43ba-9317-1563a67da199",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6136 876 1755\n"
     ]
    }
   ],
   "source": [
    "# v3: corrected 'reasoning' field, v2 has erroneous (nested/presece=No) reasonings\n",
    "num_train_examples = int(len(formatted_data)*.7)\n",
    "num_val_examples = int(len(formatted_data)*.1)\n",
    "num_test_examples = len(formatted_data) - num_train_examples - num_val_examples\n",
    "print(num_train_examples, num_val_examples, num_test_examples)\n",
    "\n",
    "random.seed(0)\n",
    "random.shuffle(formatted_data)\n",
    "with open('synth_data_gpt4/sbdh_gpt4_v3_multilabel_train.json','w') as f:\n",
    "    json.dump({'data':formatted_data[:num_train_examples]}, f)\n",
    "with open('synth_data_gpt4/sbdh_gpt4_v3_multilabel_valid.json','w') as f:\n",
    "    json.dump({'data':formatted_data[num_train_examples:num_train_examples+num_val_examples]}, f)\n",
    "with open('synth_data_gpt4/sbdh_gpt4_v3_multilabel_test.json','w') as f:\n",
    "    json.dump({'data':formatted_data[-num_test_examples:]}, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ffb7c395-2661-4ad2-8326-60f3c1f96c5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label_isolation_or_loss_of_relationship    254\n",
       "label_violence                              81\n",
       "label_transitions_of_care                   65\n",
       "label_psychiatric_symptoms_or_disorders    131\n",
       "label_legal_problems                        46\n",
       "label_housing_insecurity                    90\n",
       "label_pain                                  97\n",
       "label_financial_insecurity                 185\n",
       "label_barriers_to_care                      58\n",
       "label_patient_disability                    58\n",
       "label_substance_abuse                       94\n",
       "label_food_insecurity                       66\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('synth_data_gpt4/sbdh_gpt4_v3_multilabel_hr_valid.json') as f:\n",
    "    a = json.load(f)['data']\n",
    "pd.DataFrame(a).iloc[:,1:-2].sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d03771-b772-4cf3-b1d4-2101d69edd46",
   "metadata": {},
   "source": [
    "### Human annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf419bb2-a537-4641-afd3-ad790f5fb975",
   "metadata": {},
   "source": [
    "#### Prepare files for annotators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70900d2d-3337-4542-9e8d-6f7e5fa7d291",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8767\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Text': 'His lower back pain has been worsening over the last few weeks.',\n",
       "  'Annotations': [{'Textspan': 'lower back pain',\n",
       "    'Reasoning': 'Experiencing lower back pain is a sign of the category pain.',\n",
       "    'SBDH': 'Pain',\n",
       "    'Presence': 'yes',\n",
       "    'Period': 'current',\n",
       "    'Text': 'His lower back pain has been worsening over the last few weeks.',\n",
       "    'idx': 12819}]},\n",
       " {'Text': 'The patient has recently been laid off from his job as a construction worker and expresses concern about his financial situation.',\n",
       "  'Annotations': [{'Textspan': 'recently been laid off',\n",
       "    'Reasoning': 'The patient lost his job recently, indicating a state of job insecurity.',\n",
       "    'SBDH': 'Job Insecurity',\n",
       "    'Presence': 'yes',\n",
       "    'Period': 'current',\n",
       "    'Text': 'The patient has recently been laid off from his job as a construction worker and expresses concern about his financial situation.',\n",
       "    'idx': 947},\n",
       "   {'Textspan': 'concern about his financial situation',\n",
       "    'Reasoning': 'The patient is worried about his financial situation, indicating financial insecurity.',\n",
       "    'SBDH': 'Financial Insecurity',\n",
       "    'Presence': 'yes',\n",
       "    'Period': 'current',\n",
       "    'Text': 'The patient has recently been laid off from his job as a construction worker and expresses concern about his financial situation.',\n",
       "    'idx': 947}]}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('synth_data_gpt4/synth_data_aio_filtered_8767.json') as f:\n",
    "    synth_sbdh_data_filtered = json.load(f)\n",
    "print(len(synth_sbdh_data_filtered))\n",
    "\n",
    "num_train_examples = int(len(synth_sbdh_data_filtered)*.7)\n",
    "num_val_examples = int(len(synth_sbdh_data_filtered)*.1)\n",
    "num_test_examples = len(synth_sbdh_data_filtered) - num_train_examples - num_val_examples\n",
    "\n",
    "random.seed(0)\n",
    "random.shuffle(synth_sbdh_data_filtered)\n",
    "tr_data = synth_sbdh_data_filtered[:num_train_examples]\n",
    "val_data = synth_sbdh_data_filtered[num_train_examples:num_train_examples+num_val_examples]\n",
    "test_data = synth_sbdh_data_filtered[-num_test_examples:]\n",
    "test_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae635bf1-93c8-4567-a2a8-77e74e022bb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples: 6,136; total annotations: 10,079\n",
      "Total examples: 876; total annotations: 1,444\n",
      "Total examples: 1,755; total annotations: 2,897\n"
     ]
    }
   ],
   "source": [
    "def create_df(data):\n",
    "    anns = []\n",
    "    for idx,i in enumerate(data):\n",
    "        for ann_idx,_ in enumerate(i['Annotations']):\n",
    "            ann = i['Annotations'][ann_idx].copy()\n",
    "            ann['exmpl_no'] = idx\n",
    "            ann['ann_no'] = ann_idx\n",
    "            anns += [ann]\n",
    "    print(f'Total examples: {len(data):,}; total annotations: {len(anns):,}')\n",
    "    anns_df = pd.DataFrame(anns)\n",
    "    anns_df['Annotator']='GPT-4'\n",
    "    anns_df = anns_df[['exmpl_no','ann_no','Annotator','Text','Textspan','SBDH','Presence','Period','Reasoning']].copy()\n",
    "    return anns_df\n",
    "tr_anns_df = create_df(tr_data)\n",
    "val_anns_df = create_df(val_data)\n",
    "tst_anns_df = create_df(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f28ecba-3652-41e1-a738-7e52003ba7b6",
   "metadata": {},
   "source": [
    "##### GPT4-generated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da65b0c4-6c0d-4ec6-b4bd-55a945b60d23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exmpl_no</th>\n",
       "      <th>ann_no</th>\n",
       "      <th>Text</th>\n",
       "      <th>Textspan</th>\n",
       "      <th>SBDH</th>\n",
       "      <th>Presence</th>\n",
       "      <th>Period</th>\n",
       "      <th>Reasoning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>847</td>\n",
       "      <td>XX</td>\n",
       "      <td>His recent loss of employment and eviction has...</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644</th>\n",
       "      <td>993</td>\n",
       "      <td>XX</td>\n",
       "      <td>She frequently suffers from domestic violence ...</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1373</th>\n",
       "      <td>828</td>\n",
       "      <td>XX</td>\n",
       "      <td>Patient has been drinking heavily since the lo...</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1343</th>\n",
       "      <td>810</td>\n",
       "      <td>XX</td>\n",
       "      <td>Patient needs to take multiple buses to get to...</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1551</th>\n",
       "      <td>936</td>\n",
       "      <td>XX</td>\n",
       "      <td>Patient reported an increase in pain intensity...</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>946</td>\n",
       "      <td>XX</td>\n",
       "      <td>Patient's wife reported that he has been drink...</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>885</td>\n",
       "      <td>XX</td>\n",
       "      <td>The patient needs to find a new primary care p...</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1342</th>\n",
       "      <td>809</td>\n",
       "      <td>XX</td>\n",
       "      <td>Patient's wheelchair-bound due to a spinal cor...</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>951</td>\n",
       "      <td>XX</td>\n",
       "      <td>Patient was recently admitted for a psychiatri...</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1386</th>\n",
       "      <td>835</td>\n",
       "      <td>XX</td>\n",
       "      <td>Due to his recent layoff, patient is concerned...</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "      <td>XX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      exmpl_no ann_no                                               Text  \\\n",
       "1407       847     XX  His recent loss of employment and eviction has...   \n",
       "1644       993     XX  She frequently suffers from domestic violence ...   \n",
       "1373       828     XX  Patient has been drinking heavily since the lo...   \n",
       "1343       810     XX  Patient needs to take multiple buses to get to...   \n",
       "1551       936     XX  Patient reported an increase in pain intensity...   \n",
       "...        ...    ...                                                ...   \n",
       "1567       946     XX  Patient's wife reported that he has been drink...   \n",
       "1466       885     XX  The patient needs to find a new primary care p...   \n",
       "1342       809     XX  Patient's wheelchair-bound due to a spinal cor...   \n",
       "1575       951     XX  Patient was recently admitted for a psychiatri...   \n",
       "1386       835     XX  Due to his recent layoff, patient is concerned...   \n",
       "\n",
       "     Textspan SBDH Presence Period Reasoning  \n",
       "1407       XX   XX       XX     XX        XX  \n",
       "1644       XX   XX       XX     XX        XX  \n",
       "1373       XX   XX       XX     XX        XX  \n",
       "1343       XX   XX       XX     XX        XX  \n",
       "1551       XX   XX       XX     XX        XX  \n",
       "...       ...  ...      ...    ...       ...  \n",
       "1567       XX   XX       XX     XX        XX  \n",
       "1466       XX   XX       XX     XX        XX  \n",
       "1342       XX   XX       XX     XX        XX  \n",
       "1575       XX   XX       XX     XX        XX  \n",
       "1386       XX   XX       XX     XX        XX  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_eval_df = tst_anns_df[(tst_anns_df['exmpl_no']>=755)&(tst_anns_df['exmpl_no']<=999)].copy()\n",
    "human_eval_df.drop('Annotator',axis=1,inplace=True)\n",
    "for col in ['ann_no', 'Textspan', 'SBDH', 'Presence', 'Period', 'Reasoning']:\n",
    "    human_eval_df[col] = 'XX'\n",
    "human_eval_df.drop_duplicates(inplace=True)\n",
    "human_eval_df = human_eval_df.sample(100,random_state=0).copy()\n",
    "human_eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41618c49-a399-4be2-851a-0ab00fe1d61e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "human_eval_df.to_csv('human_eval/synthetic_sbdh_annotation_text_only_emily.csv',index=False)\n",
    "human_eval_df.to_csv('human_eval/synthetic_sbdh_annotation_text_only_raelene.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd6ad56-16d5-4b5d-b710-3c73accca33c",
   "metadata": {},
   "source": [
    "##### GPT4-generated annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df735b4b-2b71-4ca7-9737-b79790b4ccf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exmpl_no</th>\n",
       "      <th>ann_no</th>\n",
       "      <th>Annotator</th>\n",
       "      <th>Text</th>\n",
       "      <th>Textspan</th>\n",
       "      <th>SBDH</th>\n",
       "      <th>Presence</th>\n",
       "      <th>Period</th>\n",
       "      <th>Reasoning</th>\n",
       "      <th>Entities_in_same_category</th>\n",
       "      <th>Wrong_wrt_b_guidelines</th>\n",
       "      <th>Rationale_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>GPT-4</td>\n",
       "      <td>Patient has a history of substance abuse, spec...</td>\n",
       "      <td>history of substance abuse</td>\n",
       "      <td>Substance Abuse</td>\n",
       "      <td>yes</td>\n",
       "      <td>history</td>\n",
       "      <td>Explicit mention of substance abuse in the pat...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Human</td>\n",
       "      <td>-- Same as Above --</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>GPT-4</td>\n",
       "      <td>Patient has a history of substance abuse, spec...</td>\n",
       "      <td>enrolled in a substance abuse treatment program</td>\n",
       "      <td>Substance Abuse</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "      <td>Enrollment in a treatment program suggests cur...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Human</td>\n",
       "      <td>-- Same as Above --</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>GPT-4</td>\n",
       "      <td>Patient is currently on parole and has to meet...</td>\n",
       "      <td>currently on parole</td>\n",
       "      <td>Legal Problems</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "      <td>Being on parole indicates the presence of lega...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2883</th>\n",
       "      <td>874</td>\n",
       "      <td>0</td>\n",
       "      <td>Human</td>\n",
       "      <td>-- Same as Above --</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2884</th>\n",
       "      <td>874</td>\n",
       "      <td>1</td>\n",
       "      <td>GPT-4</td>\n",
       "      <td>Patient often feels lonely and isolated, and a...</td>\n",
       "      <td>avoids social interactions</td>\n",
       "      <td>Social Isolation</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "      <td>Avoidance of social interactions indicates soc...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2885</th>\n",
       "      <td>874</td>\n",
       "      <td>1</td>\n",
       "      <td>Human</td>\n",
       "      <td>-- Same as Above --</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2886</th>\n",
       "      <td>875</td>\n",
       "      <td>0</td>\n",
       "      <td>GPT-4</td>\n",
       "      <td>The veteran mentioned that he had been struggl...</td>\n",
       "      <td>struggling with alcoholism</td>\n",
       "      <td>Substance Abuse</td>\n",
       "      <td>yes</td>\n",
       "      <td>history</td>\n",
       "      <td>Struggling with alcoholism indicates substance...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2887</th>\n",
       "      <td>875</td>\n",
       "      <td>0</td>\n",
       "      <td>Human</td>\n",
       "      <td>-- Same as Above --</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2888 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      exmpl_no  ann_no Annotator  \\\n",
       "0            0       0     GPT-4   \n",
       "1            0       0     Human   \n",
       "2            0       1     GPT-4   \n",
       "3            0       1     Human   \n",
       "4            1       0     GPT-4   \n",
       "...        ...     ...       ...   \n",
       "2883       874       0     Human   \n",
       "2884       874       1     GPT-4   \n",
       "2885       874       1     Human   \n",
       "2886       875       0     GPT-4   \n",
       "2887       875       0     Human   \n",
       "\n",
       "                                                   Text  \\\n",
       "0     Patient has a history of substance abuse, spec...   \n",
       "1                                   -- Same as Above --   \n",
       "2     Patient has a history of substance abuse, spec...   \n",
       "3                                   -- Same as Above --   \n",
       "4     Patient is currently on parole and has to meet...   \n",
       "...                                                 ...   \n",
       "2883                                -- Same as Above --   \n",
       "2884  Patient often feels lonely and isolated, and a...   \n",
       "2885                                -- Same as Above --   \n",
       "2886  The veteran mentioned that he had been struggl...   \n",
       "2887                                -- Same as Above --   \n",
       "\n",
       "                                             Textspan              SBDH  \\\n",
       "0                          history of substance abuse   Substance Abuse   \n",
       "1                                                   -                 -   \n",
       "2     enrolled in a substance abuse treatment program   Substance Abuse   \n",
       "3                                                   -                 -   \n",
       "4                                 currently on parole    Legal Problems   \n",
       "...                                               ...               ...   \n",
       "2883                                                -                 -   \n",
       "2884                       avoids social interactions  Social Isolation   \n",
       "2885                                                -                 -   \n",
       "2886                       struggling with alcoholism   Substance Abuse   \n",
       "2887                                                -                 -   \n",
       "\n",
       "     Presence   Period                                          Reasoning  \\\n",
       "0         yes  history  Explicit mention of substance abuse in the pat...   \n",
       "1           -        -                                                  -   \n",
       "2         yes  current  Enrollment in a treatment program suggests cur...   \n",
       "3           -        -                                                  -   \n",
       "4         yes  current  Being on parole indicates the presence of lega...   \n",
       "...       ...      ...                                                ...   \n",
       "2883        -        -                                                  -   \n",
       "2884      yes  current  Avoidance of social interactions indicates soc...   \n",
       "2885        -        -                                                  -   \n",
       "2886      yes  history  Struggling with alcoholism indicates substance...   \n",
       "2887        -        -                                                  -   \n",
       "\n",
       "     Entities_in_same_category  Wrong_wrt_b_guidelines Rationale_rating  \n",
       "0                                                    0                -  \n",
       "1                                                    0                -  \n",
       "2                                                    0                -  \n",
       "3                                                    0                -  \n",
       "4                                                    0                -  \n",
       "...                        ...                     ...              ...  \n",
       "2883                                                 0                -  \n",
       "2884                                                 0                -  \n",
       "2885                                                 0                -  \n",
       "2886                                                 0                -  \n",
       "2887                                                 0                -  \n",
       "\n",
       "[2888 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_for_eval(anns_df):\n",
    "    anns_df = anns_df.loc[anns_df.index.repeat(2)].reset_index(drop=True)\n",
    "    anns_df['Entities_in_same_category'] = ''\n",
    "    anns_df['Wrong_wrt_b_guidelines'] = 0\n",
    "    anns_df['Rationale_rating'] = '-'\n",
    "    anns_df.loc[anns_df.index%2==1,'Annotator'] = 'Human'\n",
    "    anns_df.loc[anns_df.index%2==1,'Text'] = '-- Same as Above --'\n",
    "    anns_df.loc[anns_df.index%2==1,'Textspan'] = '-'\n",
    "    anns_df.loc[anns_df.index%2==1,'SBDH'] = '-'\n",
    "    anns_df.loc[anns_df.index%2==1,'Presence'] = '-'\n",
    "    anns_df.loc[anns_df.index%2==1,'Period'] = '-'\n",
    "    anns_df.loc[anns_df.index%2==1,'Reasoning'] = '-'\n",
    "    return anns_df\n",
    "\n",
    "tr_anns_df = format_for_eval(tr_anns_df)\n",
    "val_anns_df = format_for_eval(val_anns_df)\n",
    "tst_anns_df = format_for_eval(tst_anns_df)\n",
    "val_anns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1714,
   "id": "267865bc-b83e-4f61-bb8e-9923cfd9ae82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tr_anns_df[tr_anns_df['exmpl_no']<3068].to_csv('human_eval/synthetic_sbdh_annotation_training_emily.csv',index=False)\n",
    "tr_anns_df[tr_anns_df['exmpl_no']>3067].to_csv('human_eval/synthetic_sbdh_annotation_training_raelene.csv',index=False)\n",
    "val_anns_df[val_anns_df['exmpl_no']<438].to_csv('human_eval/synthetic_sbdh_annotation_val_emily.csv',index=False)\n",
    "val_anns_df[val_anns_df['exmpl_no']>437].to_csv('human_eval/synthetic_sbdh_annotation_val_raelene.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1154598f-ab34-4bce-a4ca-80bdf0f3b610",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exmpl_no</th>\n",
       "      <th>ann_no</th>\n",
       "      <th>Annotator</th>\n",
       "      <th>Text</th>\n",
       "      <th>Textspan</th>\n",
       "      <th>SBDH</th>\n",
       "      <th>Presence</th>\n",
       "      <th>Period</th>\n",
       "      <th>Reasoning</th>\n",
       "      <th>Entities_in_same_category</th>\n",
       "      <th>Wrong_wrt_b_guidelines</th>\n",
       "      <th>Rationale_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1448</th>\n",
       "      <td>438</td>\n",
       "      <td>0</td>\n",
       "      <td>GPT-4</td>\n",
       "      <td>The patient has a restraining order against he...</td>\n",
       "      <td>restraining order against her ex-husband</td>\n",
       "      <td>Legal Problems</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "      <td>A restraining order indicates a legal problem ...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1449</th>\n",
       "      <td>438</td>\n",
       "      <td>0</td>\n",
       "      <td>Human</td>\n",
       "      <td>-- Same as Above --</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1450</th>\n",
       "      <td>438</td>\n",
       "      <td>1</td>\n",
       "      <td>GPT-4</td>\n",
       "      <td>The patient has a restraining order against he...</td>\n",
       "      <td>living in a shelter for domestic abuse victims</td>\n",
       "      <td>Housing Insecurity</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "      <td>Living in a shelter due to domestic abuse indi...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>438</td>\n",
       "      <td>1</td>\n",
       "      <td>Human</td>\n",
       "      <td>-- Same as Above --</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      exmpl_no  ann_no Annotator  \\\n",
       "1448       438       0     GPT-4   \n",
       "1449       438       0     Human   \n",
       "1450       438       1     GPT-4   \n",
       "1451       438       1     Human   \n",
       "\n",
       "                                                   Text  \\\n",
       "1448  The patient has a restraining order against he...   \n",
       "1449                                -- Same as Above --   \n",
       "1450  The patient has a restraining order against he...   \n",
       "1451                                -- Same as Above --   \n",
       "\n",
       "                                            Textspan                SBDH  \\\n",
       "1448        restraining order against her ex-husband      Legal Problems   \n",
       "1449                                               -                   -   \n",
       "1450  living in a shelter for domestic abuse victims  Housing Insecurity   \n",
       "1451                                               -                   -   \n",
       "\n",
       "     Presence   Period                                          Reasoning  \\\n",
       "1448      yes  current  A restraining order indicates a legal problem ...   \n",
       "1449        -        -                                                  -   \n",
       "1450      yes  current  Living in a shelter due to domestic abuse indi...   \n",
       "1451        -        -                                                  -   \n",
       "\n",
       "     Entities_in_same_category  Wrong_wrt_b_guidelines Rationale_rating  \n",
       "1448                                                 0                -  \n",
       "1449                                                 0                -  \n",
       "1450                                                 0                -  \n",
       "1451                                                 0                -  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_anns_df[val_anns_df['exmpl_no']==438]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "af3e05e9-54fa-4749-ad7d-70d93ed330e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tst_anns_df[tst_anns_df['exmpl_no']<1000].to_csv('human_eval/synthetic_sbdh_annotation_emily.csv',index=False)\n",
    "tst_anns_df[tst_anns_df['exmpl_no']>754].to_csv('human_eval/synthetic_sbdh_annotation_raelene.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9ebaa1-2ad3-443a-ba8a-1f0b95499742",
   "metadata": {},
   "source": [
    "#### Read ann files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc44bbf-5856-47dc-9283-345b3e56e425",
   "metadata": {},
   "source": [
    "##### GPT4-generated annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3729879c-5b30-469c-a339-9cf7f46185a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raelene_ann = pd.read_csv('human_eval/synthetic_sbdh_annotation_raelene_adj_v2.csv',encoding='UTF-8')\n",
    "raelene_ann['exmpl_ann_no'] = raelene_ann.apply(lambda x:str(x['exmpl_no'])+'-'+str(x['ann_no']),axis=1)\n",
    "\n",
    "emily_ann = pd.read_csv('human_eval/synthetic_sbdh_annotation_emily_adj_v2.csv',encoding='UTF-8')\n",
    "emily_ann['exmpl_ann_no'] = emily_ann.apply(lambda x:str(x['exmpl_no'])+'-'+str(x['ann_no']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef42de7e-a364-4447-a6d6-6853958a7d4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples: 1,000, Total annotations: 1,984 Total annotations by GPT-4: 1,646\n",
      "New annotations added: 338(20.53)%\n",
      "Average ratings for 1646 rationales >> 3.726609963547995\n",
      "Distribution of ratings >> {1: 66, 2: 84, 3: 84, 4: 1412}\n",
      "Annotations wrong with respect to broader guidelines >> 49\n",
      "GPT-4 annotations updated: 293(17.80)%\n",
      "GPT-4 annotations updated (relaxed): 219(13.30)%\n"
     ]
    }
   ],
   "source": [
    "ratings = [int(i) for i in raelene_ann[raelene_ann['Annotator']=='GPT-4']['Rationale_rating'].tolist()]\n",
    "\n",
    "tot_ann_count = raelene_ann['exmpl_ann_no'].nunique()\n",
    "gpt4_ann_count = raelene_ann[raelene_ann['Annotator']=='GPT-4']['exmpl_ann_no'].nunique()\n",
    "new_ann_count = tot_ann_count-gpt4_ann_count\n",
    "print(f\"Total examples: {raelene_ann['exmpl_no'].nunique():,}, \\\n",
    "Total annotations: {tot_ann_count:,} \\\n",
    "Total annotations by GPT-4: {gpt4_ann_count:,}\")\n",
    "print(f'New annotations added: {new_ann_count}({(new_ann_count)*100/gpt4_ann_count:.2f})%')\n",
    "print(f'Average ratings for {len(ratings)} rationales >> {sum(ratings)/len(ratings)}')\n",
    "print('Distribution of ratings >>',{k: v for k, v in sorted(dict(Counter(ratings)).items(), key=lambda v: v[0])})\n",
    "print(f\"Annotations wrong with respect to broader guidelines >> {raelene_ann['Wrong_wrt_b_guidelines'].sum()}\")\n",
    "\n",
    "df = raelene_ann[raelene_ann['Annotator']=='Human']\n",
    "modified_ann_count = df[(df['Textspan']!='-')|(df['SBDH']!='-')|(df['Presence']!='-')|(df['Period']!='-')].shape[0]\n",
    "print(f'GPT-4 annotations updated: {modified_ann_count-new_ann_count}({(modified_ann_count-new_ann_count)*100/gpt4_ann_count:.2f})%')\n",
    "relaxed_modified_ann_count = df[(df['SBDH']!='-')|(df['Presence']!='-')|(df['Period']!='-')].shape[0]\n",
    "print(f'GPT-4 annotations updated (relaxed): {relaxed_modified_ann_count-new_ann_count}({(relaxed_modified_ann_count-new_ann_count)*100/gpt4_ann_count:.2f})%')\n",
    "# print(df[df['Textspan']!='-'].shape[0],df[df['SBDH']!='-'].shape[0],df[df['Presence']!='-'].shape[0],df[df['Period']!='-'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74f62c8b-536c-4abd-bc0b-bd902e7ef4da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples: 1,000, Total annotations: 1,977 Total annotations by GPT-4: 1,661\n",
      "New annotations added: 316(19.02)%\n",
      "Average ratings for 1661 rationales >> 3.624924744130042\n",
      "Distribution of ratings >> {1: 142, 2: 32, 3: 133, 4: 1354}\n",
      "Annotations wrong with respect to broader guidelines >> 103.0\n",
      "GPT-4 annotations updated: 307(18.48)%\n",
      "GPT-4 annotations updated (relaxed): 246(14.81)%\n"
     ]
    }
   ],
   "source": [
    "ratings = [int(i) for i in emily_ann[emily_ann['Annotator']=='GPT-4']['Rationale_rating'].tolist()]    \n",
    "\n",
    "tot_ann_count = emily_ann['exmpl_ann_no'].nunique()\n",
    "gpt4_ann_count = emily_ann[emily_ann['Annotator']=='GPT-4']['exmpl_ann_no'].nunique()\n",
    "new_ann_count = tot_ann_count-gpt4_ann_count\n",
    "print(f\"Total examples: {emily_ann['exmpl_no'].nunique():,}, \\\n",
    "Total annotations: {tot_ann_count:,} \\\n",
    "Total annotations by GPT-4: {gpt4_ann_count:,}\")\n",
    "print(f'New annotations added: {new_ann_count}({(new_ann_count)*100/gpt4_ann_count:.2f})%')\n",
    "print(f'Average ratings for {len(ratings)} rationales >> {sum(ratings)/len(ratings)}')\n",
    "print('Distribution of ratings >>',{k: v for k, v in sorted(dict(Counter(ratings)).items(), key=lambda v: v[0])})\n",
    "print(f\"Annotations wrong with respect to broader guidelines >> {emily_ann['Wrong_wrt_b_guidelines'].sum()}\")\n",
    "\n",
    "df = emily_ann[emily_ann['Annotator']=='Human']\n",
    "modified_ann_count = df[(df['Textspan']!='-')|(df['SBDH']!='-')|(df['Presence']!='-')|(df['Period']!='-')].shape[0]\n",
    "print(f'GPT-4 annotations updated: {modified_ann_count-new_ann_count}({(modified_ann_count-new_ann_count)*100/gpt4_ann_count:.2f})%')\n",
    "relaxed_modified_ann_count = df[(df['SBDH']!='-')|(df['Presence']!='-')|(df['Period']!='-')].shape[0]\n",
    "print(f'GPT-4 annotations updated (relaxed): {relaxed_modified_ann_count-new_ann_count}({(relaxed_modified_ann_count-new_ann_count)*100/gpt4_ann_count:.2f})%')\n",
    "# print(df[df['Textspan']!='-'].shape[0],df[df['SBDH']!='-'].shape[0],df[df['Presence']!='-'].shape[0],df[df['Period']!='-'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f1b00851-f9c5-488a-bc3b-6aac1c20298d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ecbc26c3fe4f88a8b168e1b603986b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6136 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total annotations: 11630\n",
      "Correct annotations: strict --> 8248, relaxed --> 8895\n",
      "Discarded annotations: 468(4.02%)\n",
      "Incorrect annotations: strict --> 1386(11.92%), relaxed --> 739(6.35%)\n",
      "Missing annotations: 1528(13.14%)\n",
      "Human-LLM alignment: strict --> 70.92, relaxed --> 76.48\n"
     ]
    }
   ],
   "source": [
    "final_ann, ann_collapsed = [], []\n",
    "split='train' # <<< CHECK THIS BEFORE EXECUTING THE CELL ⚠️\n",
    "\n",
    "if split == 'train':\n",
    "    raelene_ann = pd.read_csv('human_eval/synthetic_sbdh_annotation_training_raelene_cmplt.csv',encoding='UTF-8')\n",
    "    raelene_ann['exmpl_ann_no'] = raelene_ann.apply(lambda x:str(x['exmpl_no'])+'-'+str(x['ann_no']),axis=1)\n",
    "    emily_ann = pd.read_csv('human_eval/synthetic_sbdh_annotation_training_emily_cmplt.csv',encoding='UTF-8')\n",
    "    emily_ann['exmpl_ann_no'] = emily_ann.apply(lambda x:str(x['exmpl_no'])+'-'+str(x['ann_no']),axis=1)\n",
    "\n",
    "    df = pd.concat([\n",
    "        emily_ann.copy(),\n",
    "        raelene_ann.copy()\n",
    "    ], ignore_index=True, sort=False)\n",
    "    annotator_id = 'cmbd'\n",
    "elif split =='val':\n",
    "    raelene_ann = pd.read_csv('human_eval/synthetic_sbdh_annotation_val_raelene_cmplt.csv',encoding='UTF-8')\n",
    "    raelene_ann['exmpl_ann_no'] = raelene_ann.apply(lambda x:str(x['exmpl_no'])+'-'+str(x['ann_no']),axis=1)\n",
    "    emily_ann = pd.read_csv('human_eval/synthetic_sbdh_annotation_val_emily_cmplt.csv',encoding='UTF-8')\n",
    "    emily_ann['exmpl_ann_no'] = emily_ann.apply(lambda x:str(x['exmpl_no'])+'-'+str(x['ann_no']),axis=1)\n",
    "\n",
    "    df = pd.concat([\n",
    "        emily_ann.copy(),\n",
    "        raelene_ann.copy()\n",
    "    ], ignore_index=True, sort=False)\n",
    "    annotator_id = 'cmbd'\n",
    "elif split=='test':\n",
    "    # raelene_ann = pd.read_csv('human_eval/synthetic_sbdh_annotation_raelene_cmplt.csv',encoding='UTF-8')\n",
    "    # raelene_ann['exmpl_ann_no'] = raelene_ann.apply(lambda x:str(x['exmpl_no'])+'-'+str(x['ann_no']),axis=1)\n",
    "    # emily_ann = pd.read_csv('human_eval/synthetic_sbdh_annotation_emily_cmplt.csv',encoding='UTF-8')\n",
    "    # emily_ann['exmpl_ann_no'] = emily_ann.apply(lambda x:str(x['exmpl_no'])+'-'+str(x['ann_no']),axis=1)\n",
    "\n",
    "    # df = emily_ann.copy()\n",
    "    # annotator_id = 'ann_1'\n",
    "    # df = raelene_ann.copy()\n",
    "    # annotator_id = 'ann_2'\n",
    "\n",
    "    raelene_ann = pd.read_csv('human_eval/synthetic_sbdh_annotation_raelene_adj_v2.csv',encoding='UTF-8')\n",
    "    raelene_ann['exmpl_ann_no'] = raelene_ann.apply(lambda x:str(x['exmpl_no'])+'-'+str(x['ann_no']),axis=1)\n",
    "    emily_ann = pd.read_csv('human_eval/synthetic_sbdh_annotation_emily_adj_v2.csv',encoding='UTF-8')\n",
    "    emily_ann['exmpl_ann_no'] = emily_ann.apply(lambda x:str(x['exmpl_no'])+'-'+str(x['ann_no']),axis=1)\n",
    "    df = pd.concat([\n",
    "        emily_ann.copy(),\n",
    "        raelene_ann[raelene_ann['exmpl_no']>=1000].copy()\n",
    "    ], ignore_index=True, sort=False)\n",
    "    annotator_id = 'cmbd'\n",
    "\n",
    "ann_correct, ann_discard, ann_update, ann_new = 0, 0, 0, 0\n",
    "ann_correct_relaxed, ann_update_relaxed = 0, 0\n",
    "\n",
    "unq_exmpls = df['exmpl_no'].unique().tolist()\n",
    "for ex_id in tqdm(unq_exmpls):\n",
    "    # if ex_id in [1081]:continue\n",
    "    temp_df = df[df['exmpl_no']==ex_id].reset_index()\n",
    "    cur_ann_dict = {\n",
    "        'Text':temp_df.iloc[0]['Text'],\n",
    "        'idx':ex_id,\n",
    "        'Annotations':[]\n",
    "    }\n",
    "    \n",
    "    # 1. Check if the rows follow this pattern >> GPT-4, Human, GPT-4, Human,... or GPT-4, Human, Human,...\n",
    "    # There can not be any more than 1 annotator=Human row between annotator=GPT-4 rows      \n",
    "    every_other_ann_list = temp_df.iloc[::2]['Annotator'].tolist()\n",
    "    for i,ann in enumerate(every_other_ann_list):\n",
    "        if ann=='Human':\n",
    "            assert 'GPT-4' not in every_other_ann_list[i+1:]\n",
    "            continue\n",
    "    \n",
    "    # 2. Group in pairs and get all annotations\n",
    "    # ann_no = 0\n",
    "    for i, g in temp_df.groupby(temp_df.index // 2):\n",
    "        if g.iloc[0]['Annotator']=='GPT-4':\n",
    "            assert g['ann_no'].nunique()==1, f\"There can be only one unique `ann_no` in a pair but got {g['ann_no'].nunique()}.\"\n",
    "            assert g.shape[0]==2, f\"Should be a size of 2 but got {g.shape[0]}.\"\n",
    "            # Case 1: GPT-4 annotation is corrcet, will KEEP it\n",
    "            if g.iloc[-1]['Textspan'].strip()=='-' and g.iloc[-1]['SBDH'].strip()=='-' and g.iloc[-1]['Presence'].strip()=='-' and g.iloc[-1]['Period'].strip()=='-':\n",
    "                cur_ann_dict['Annotations'] += [{\n",
    "                    'ex_no':ex_id,\n",
    "                    'ann_no':int(g.iloc[0]['ann_no']),\n",
    "                    'Text':temp_df.iloc[0]['Text'].strip(),\n",
    "                    'Textspan':g.iloc[0]['Textspan'].strip(),\n",
    "                    'SBDH':g.iloc[0]['SBDH'].strip(),\n",
    "                    'Presence':g.iloc[0]['Presence'].strip().lower(),\n",
    "                    'Period':g.iloc[0]['Period'].strip().lower(),\n",
    "                    'Reasoning':g.iloc[0]['Reasoning'].strip() if g.iloc[0]['Rationale_rating']==4 else g.iloc[-1]['Reasoning'].strip(),\n",
    "                    'Operation':'keep',\n",
    "                    'Rating':int(g.iloc[0]['Rationale_rating']),\n",
    "                    'Annotator':annotator_id\n",
    "                }]\n",
    "                ann_correct += 1\n",
    "            # Case 2: GPT-4 annotated unnecessarily, need to DISCARD \n",
    "            elif g.iloc[-1]['Textspan'].strip()=='XXX' or g.iloc[-1]['SBDH'].strip()=='XXX' or g.iloc[-1]['Presence'].strip()=='XXX' or g.iloc[-1]['Period'].strip()=='XXX':\n",
    "                cur_ann_dict['Annotations'] += [{\n",
    "                    'ex_no':ex_id,\n",
    "                    'ann_no':int(g.iloc[0]['ann_no']),\n",
    "                    'Text':'XXX',\n",
    "                    'Textspan':'XXX',\n",
    "                    'SBDH':g.iloc[0]['SBDH'].strip(),\n",
    "                    'Presence':'XXX',\n",
    "                    'Period':'XXX',\n",
    "                    'Reasoning':'XXX',\n",
    "                    'Operation':'discard',\n",
    "                    'Rating':int(g.iloc[0]['Rationale_rating']),\n",
    "                    'Annotator':annotator_id\n",
    "                }]\n",
    "                ann_discard += 1\n",
    "            # Case 3: GPT-4 is wrong, need to correct it\n",
    "            else:\n",
    "                cur_ann_dict['Annotations'] += [{\n",
    "                    'ex_no':ex_id,\n",
    "                    'ann_no':int(g.iloc[0]['ann_no']),\n",
    "                    'Text':temp_df.iloc[0]['Text'].strip(),\n",
    "                    'Textspan':g.iloc[0]['Textspan'].strip() if g.iloc[-1]['Textspan'].strip()=='-' else g.iloc[-1]['Textspan'].strip(),\n",
    "                    'SBDH':g.iloc[0]['SBDH'].strip() if g.iloc[-1]['SBDH'].strip()=='-' else g.iloc[-1]['SBDH'].strip(),\n",
    "                    'Presence':g.iloc[0]['Presence'].strip().lower() if g.iloc[-1]['Presence'].strip()=='-' else g.iloc[-1]['Presence'].strip().lower(),\n",
    "                    'Period':g.iloc[0]['Period'].strip().lower() if g.iloc[-1]['Period'].strip()=='-' else g.iloc[-1]['Period'].strip().lower(),\n",
    "                    'Reasoning':g.iloc[0]['Reasoning'].strip() if g.iloc[0]['Rationale_rating']==4 else g.iloc[-1]['Reasoning'].strip(),\n",
    "                    'Operation':'correct',\n",
    "                    'Rating':int(g.iloc[0]['Rationale_rating']),\n",
    "                    'Annotator':annotator_id\n",
    "                }]\n",
    "                # if g.iloc[0]['Rationale_rating']==4 and g.iloc[-1]['SBDH'].strip()!='-':print(ex_id,int(g.iloc[0]['ann_no']))\n",
    "                ann_update += 1\n",
    "                if g.iloc[-1]['SBDH'].strip()=='-' and g.iloc[-1]['Presence'].strip()=='-' and g.iloc[-1]['Period'].strip()=='-': # relaxed matching\n",
    "                    ann_correct_relaxed += 1\n",
    "                    cur_ann_dict['Annotations'][-1]['Operation']='keep'\n",
    "                else:\n",
    "                    ann_update_relaxed += 1\n",
    "            # ann_no += 1\n",
    "        else: # Case 4: annotator is Human, new annotations, ADD all\n",
    "            for g_row_id in range(g.shape[0]):\n",
    "                cur_ann_dict['Annotations'] += [{\n",
    "                    'ex_no':ex_id,\n",
    "                    'ann_no':int(g.iloc[g_row_id]['ann_no']),\n",
    "                    'Text':temp_df.iloc[0]['Text'].strip(),\n",
    "                    'Textspan':g.iloc[g_row_id]['Textspan'].strip(),\n",
    "                    'SBDH':g.iloc[g_row_id]['SBDH'].strip(),\n",
    "                    'Presence':g.iloc[g_row_id]['Presence'].strip().lower(),\n",
    "                    'Period':g.iloc[g_row_id]['Period'].strip().lower(),\n",
    "                    'Reasoning':g.iloc[g_row_id]['Reasoning'].strip(),\n",
    "                    'Operation':'add',\n",
    "                    'Rating':-999999,\n",
    "                    'Annotator':annotator_id\n",
    "                }] \n",
    "                # ann_no += 1\n",
    "                ann_new += 1\n",
    "                \n",
    "    final_ann += [cur_ann_dict]\n",
    "    ann_collapsed += cur_ann_dict['Annotations']\n",
    "\n",
    "with open(f'human_eval/sbdh_gpt4_v3_{split}_{annotator_id}_consolidated.json','w') as f:\n",
    "    json.dump(final_ann, f)\n",
    "pd.DataFrame(ann_collapsed).to_csv(f'human_eval/sbdh_gpt4_v3_{split}_{annotator_id}_consolidated.csv',index=False)\n",
    "\n",
    "ann_total = (ann_correct+ann_discard+ann_update+ann_new)\n",
    "print(f'Total annotations: {ann_total}')\n",
    "print(f'Correct annotations: strict --> {ann_correct}, relaxed --> {ann_correct+ann_correct_relaxed}')\n",
    "print(f'Discarded annotations: {ann_discard}({ann_discard*100/ann_total:.2f}%)')\n",
    "print(f'Incorrect annotations: strict --> {ann_update}({ann_update*100/ann_total:.2f}%), relaxed --> {ann_update_relaxed}({ann_update_relaxed*100/ann_total:.2f}%)')\n",
    "print(f'Missing annotations: {ann_new}({ann_new*100/ann_total:.2f}%)')\n",
    "print(f'Human-LLM alignment: strict --> {ann_correct*100/ann_total:.2f}, relaxed --> {(ann_correct+ann_correct_relaxed)*100/ann_total:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "affe149d-fa3a-42e3-a454-f80291326a23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1732 3345\n"
     ]
    }
   ],
   "source": [
    "# sanity check, ensure that there is no empty field\n",
    "df = pd.read_csv(f'human_eval/sbdh_gpt4_v3_{split}_cmbd_consolidated.csv')\n",
    "for col in df.columns.tolist()[2:-2]:\n",
    "    assert df[df[col]=='-'].shape[0]==0 \n",
    "    assert df[pd.isna(df[col])].shape[0]==0\n",
    "print(df[df['Operation']!='discard']['ex_no'].nunique(),df[df['Operation']!='discard'].shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "385ea306-3d65-44b2-9b02-d531ef41a781",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### keep ###\n",
      "{'Job Insecurity': 0.11581920903954802, 'Social Isolation': 0.11057304277643261, 'Psychiatric Symptoms or Disorders': 0.10774818401937046, 'Financial Insecurity': 0.08555286521388217, 'Substance Abuse': 0.0847457627118644, 'Pain': 0.07909604519774012, 'Housing Insecurity': 0.07183212267958031, 'Patient Disability': 0.05407586763518967, 'Loss of Relationship': 0.05367231638418079, 'Violence': 0.0516545601291364, 'Food Insecurity': 0.04963680387409201, 'Transitions of Care': 0.04600484261501211, 'Legal Problems': 0.03833736884584342, 'Barriers to Care': 0.035916061339790153, 'Physical Isolation': 0.01533494753833737}\n",
      "### add ###\n",
      "{'Social Isolation': 0.16179001721170397, 'Loss of Relationship': 0.12220309810671257, 'Housing Insecurity': 0.11703958691910499, 'Psychiatric Symptoms or Disorders': 0.09982788296041308, 'Job Insecurity': 0.07917383820998279, 'Financial Insecurity': 0.0774526678141136, 'Violence': 0.0757314974182444, 'Barriers to Care': 0.04475043029259897, 'Substance Abuse': 0.0378657487091222, 'Transitions of Care': 0.03614457831325301, 'Pain': 0.03442340791738382, 'Physical Isolation': 0.03098106712564544, 'Legal Problems': 0.029259896729776247, 'Patient Disability': 0.027538726333907058, 'Food Insecurity': 0.025817555938037865}\n",
      "### discard ###\n",
      "{'Psychiatric Symptoms or Disorders': 0.20422535211267606, 'Patient Disability': 0.18309859154929578, 'Transitions of Care': 0.176056338028169, 'Barriers to Care': 0.1267605633802817, 'Food Insecurity': 0.08450704225352113, 'Physical Isolation': 0.07042253521126761, 'Substance Abuse': 0.04929577464788732, 'Violence': 0.028169014084507043, 'Loss of Relationship': 0.02112676056338028, 'Financial Insecurity': 0.02112676056338028, 'Pain': 0.007042253521126761, 'Socioeconomic Status': 0.007042253521126761, 'Education': 0.007042253521126761, 'Legal Problems': 0.007042253521126761, 'Job Insecurity': 0.007042253521126761}\n",
      "### correct ###\n",
      "{'Loss of Relationship': 0.17832167832167833, 'Substance Abuse': 0.13286713286713286, 'Social Isolation': 0.12237762237762238, 'Housing Insecurity': 0.10139860139860139, 'Violence': 0.08741258741258741, 'Physical Isolation': 0.06293706293706294, 'Legal Problems': 0.05244755244755245, 'Psychiatric Symptoms or Disorders': 0.045454545454545456, 'Pain': 0.045454545454545456, 'Job Insecurity': 0.045454545454545456, 'Patient Disability': 0.038461538461538464, 'Financial Insecurity': 0.03496503496503497, 'Transitions of Care': 0.03146853146853147, 'Food Insecurity': 0.01048951048951049, 'Barriers to Care': 0.01048951048951049}\n"
     ]
    }
   ],
   "source": [
    "# stats\n",
    "for opt in df['Operation'].unique():\n",
    "    print('###',opt,'###')\n",
    "    print(df[df['Operation']==opt]['SBDH'].value_counts(normalize=True).to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3cc0565c-4aed-4d1c-9f4b-8c04027248b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pain >>> {'keep': 196, 'add': 20, 'correct': 13, 'discard': 1} 230\n",
      "Job Insecurity >>> {'keep': 287, 'add': 46, 'correct': 13, 'discard': 1} 347\n",
      "Financial Insecurity >>> {'keep': 212, 'add': 45, 'correct': 10, 'discard': 3} 270\n",
      "Barriers to Care >>> {'keep': 89, 'add': 26, 'discard': 18, 'correct': 3} 136\n",
      "Loss of Relationship >>> {'keep': 133, 'add': 71, 'correct': 51, 'discard': 3} 258\n",
      "Psychiatric Symptoms or Disorders >>> {'keep': 267, 'add': 58, 'discard': 29, 'correct': 13} 367\n",
      "Transitions of Care >>> {'keep': 114, 'discard': 25, 'add': 21, 'correct': 9} 169\n",
      "Social Isolation >>> {'keep': 274, 'add': 94, 'correct': 35} 403\n",
      "Food Insecurity >>> {'keep': 123, 'add': 15, 'discard': 12, 'correct': 3} 153\n",
      "Patient Disability >>> {'keep': 134, 'discard': 26, 'add': 16, 'correct': 11} 187\n",
      "Physical Isolation >>> {'keep': 38, 'correct': 18, 'add': 18, 'discard': 10} 84\n",
      "Violence >>> {'keep': 128, 'add': 44, 'correct': 25, 'discard': 4} 201\n",
      "Legal Problems >>> {'keep': 95, 'add': 17, 'correct': 15, 'discard': 1} 128\n",
      "Substance Abuse >>> {'keep': 210, 'correct': 38, 'add': 22, 'discard': 7} 277\n",
      "Housing Insecurity >>> {'keep': 178, 'add': 68, 'correct': 29} 275\n",
      "Socioeconomic Status >>> {'discard': 1} 1\n",
      "Education >>> {'discard': 1} 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "keep       2478\n",
       "add         581\n",
       "correct     286\n",
       "discard     142\n",
       "Name: Operation, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for sbdh in df['SBDH'].unique():\n",
    "    print(sbdh, '>>>',df[df['SBDH']==sbdh]['Operation'].value_counts().to_dict(),df[df['SBDH']==sbdh].shape[0])\n",
    "df['Operation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "arabic-twist",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pain >>> {'keep': 0.8521739130434782, 'add': 0.08695652173913043, 'correct': 0.05652173913043478, 'discard': 0.004347826086956522}\n",
      "Job Insecurity >>> {'keep': 0.8270893371757925, 'add': 0.13256484149855907, 'correct': 0.037463976945244955, 'discard': 0.002881844380403458}\n",
      "Financial Insecurity >>> {'keep': 0.7851851851851852, 'add': 0.16666666666666666, 'correct': 0.037037037037037035, 'discard': 0.011111111111111112}\n",
      "Barriers to Care >>> {'keep': 0.6544117647058824, 'add': 0.19117647058823528, 'discard': 0.1323529411764706, 'correct': 0.022058823529411766}\n",
      "Loss of Relationship >>> {'keep': 0.5155038759689923, 'add': 0.2751937984496124, 'correct': 0.19767441860465115, 'discard': 0.011627906976744186}\n",
      "Psychiatric Symptoms or Disorders >>> {'keep': 0.7275204359673024, 'add': 0.15803814713896458, 'discard': 0.07901907356948229, 'correct': 0.035422343324250684}\n",
      "Transitions of Care >>> {'keep': 0.6745562130177515, 'discard': 0.14792899408284024, 'add': 0.1242603550295858, 'correct': 0.05325443786982249}\n",
      "Social Isolation >>> {'keep': 0.6799007444168734, 'add': 0.23325062034739455, 'correct': 0.08684863523573201}\n",
      "Food Insecurity >>> {'keep': 0.803921568627451, 'add': 0.09803921568627451, 'discard': 0.0784313725490196, 'correct': 0.0196078431372549}\n",
      "Patient Disability >>> {'keep': 0.7165775401069518, 'discard': 0.13903743315508021, 'add': 0.0855614973262032, 'correct': 0.058823529411764705}\n",
      "Physical Isolation >>> {'keep': 0.4523809523809524, 'correct': 0.21428571428571427, 'add': 0.21428571428571427, 'discard': 0.11904761904761904}\n",
      "Violence >>> {'keep': 0.6368159203980099, 'add': 0.21890547263681592, 'correct': 0.12437810945273632, 'discard': 0.01990049751243781}\n",
      "Legal Problems >>> {'keep': 0.7421875, 'add': 0.1328125, 'correct': 0.1171875, 'discard': 0.0078125}\n",
      "Substance Abuse >>> {'keep': 0.7581227436823105, 'correct': 0.1371841155234657, 'add': 0.07942238267148015, 'discard': 0.02527075812274368}\n",
      "Housing Insecurity >>> {'keep': 0.6472727272727272, 'add': 0.24727272727272728, 'correct': 0.10545454545454545}\n",
      "Socioeconomic Status >>> {'discard': 1.0}\n",
      "Education >>> {'discard': 1.0}\n"
     ]
    }
   ],
   "source": [
    "for sbdh in df['SBDH'].unique():\n",
    "    print(sbdh, '>>>',df[df['SBDH']==sbdh]['Operation'].value_counts(normalize=True).to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e82e026-005a-4fba-a001-53304ffd00bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'yes': 3240, 'XXX': 142, 'no': 105}\n",
      "{'current': 3017, 'history': 198, 'XXX': 142, 'unclear': 130}\n"
     ]
    }
   ],
   "source": [
    "print(df['Presence'].value_counts().to_dict())\n",
    "print(df['Period'].value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed085a67-75a7-4563-a21b-cb946ef0bb91",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6631108052305574"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Operation']!='add']['Rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a914479-6f34-451e-aa04-8d5e20dc2dbc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    2416\n",
       "3     197\n",
       "1     196\n",
       "2      97\n",
       "Name: Rating, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['Operation']!='add']['Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85940622-3100-4bb9-ad14-5eefa51027df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "rating_dict = df[df['Operation']!='add']['Rating'].value_counts().to_dict()\n",
    "rating_dict = dict(sorted(rating_dict.items(), key=lambda item: item[0]))\n",
    "plt.bar(list(map(str,rating_dict.keys())),rating_dict.values())\n",
    "plt.xlabel('Rationale rating')\n",
    "plt.ylabel('No. of examples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd346b9c-d245-456d-b5c7-1039169b1418",
   "metadata": {},
   "source": [
    "#### Agreement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fce847-b6ce-4644-99cd-2f356a6b4f43",
   "metadata": {},
   "source": [
    "##### GPT4-generated text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ade671dc-73b4-4d86-ab5c-12d8d2a6592b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "raelene_ann = pd.read_csv('human_eval/synthetic_sbdh_annotation_text_only_raelene_cmplt_v2.csv',encoding='UTF-8')\n",
    "raelene_ann['exmpl_ann_no'] = raelene_ann.apply(lambda x:str(x['exmpl_no'])+'-'+str(x['ann_no']),axis=1)\n",
    "raelene_ann['SBDH'] = raelene_ann['SBDH'].apply(lambda x: x.lower())\n",
    "raelene_ann['Annotator'] = 'Raelene'\n",
    "textspan_match = raelene_ann.apply(lambda x: 1 if x['Textspan'] in x['Text'] else 0, axis=1) # check `Textspan` is a substring from `Text`\n",
    "assert sum(textspan_match) == len(raelene_ann)\n",
    "assert raelene_ann['exmpl_ann_no'].nunique() == len(raelene_ann)\n",
    "\n",
    "emily_ann = pd.read_csv('human_eval/synthetic_sbdh_annotation_text_only_emily_cmplt_v2.csv',encoding='UTF-8')\n",
    "emily_ann['exmpl_ann_no'] = emily_ann.apply(lambda x:str(x['exmpl_no'])+'-'+str(x['ann_no']),axis=1)\n",
    "emily_ann['Presence'] = emily_ann['Presence'].apply(lambda x: 'yes' if x=='present' else 'no')\n",
    "emily_ann['SBDH'] = emily_ann['SBDH'].apply(lambda x: x.lower())\n",
    "emily_ann['Annotator'] = 'Emily'\n",
    "textspan_match = emily_ann.apply(lambda x: 1 if x['Textspan'] in x['Text'] else 0, axis=1) # check `Textspan` is a substring from `Text`\n",
    "assert sum(textspan_match) == len(emily_ann)\n",
    "assert emily_ann['exmpl_ann_no'].nunique() == len(emily_ann)\n",
    "\n",
    "adj_ann = pd.read_csv('human_eval/synthetic_sbdh_annotation_text_only_adjudicated_v2.csv',encoding='UTF-8')\n",
    "adj_ann['exmpl_ann_no'] = adj_ann.apply(lambda x:str(x['exmpl_no'])+'-'+str(x['ann_no']),axis=1)\n",
    "adj_ann['Presence'] = adj_ann['Presence'].apply(lambda x: 'yes' if x=='present' else 'no')\n",
    "adj_ann['SBDH'] = adj_ann['SBDH'].apply(lambda x: x.lower())\n",
    "adj_ann['Annotator'] = 'Adjudicated'\n",
    "textspan_match = adj_ann.apply(lambda x: 1 if x['Textspan'] in x['Text'] else 0, axis=1) # check `Textspan` is a substring from `Text`\n",
    "assert sum(textspan_match) == len(adj_ann)\n",
    "assert adj_ann['exmpl_ann_no'].nunique() == len(adj_ann)\n",
    "\n",
    "gpt4_ann = pd.read_csv('human_eval/synthetic_sbdh_annotation_raelene_adj_v2.csv',encoding='UTF-8').iloc[:,:-3].copy()\n",
    "gpt4_ann = gpt4_ann[gpt4_ann['Annotator']=='GPT-4'].copy()\n",
    "gpt4_ann = gpt4_ann[gpt4_ann['exmpl_no'].isin(emily_ann['exmpl_no'].unique())].copy()\n",
    "gpt4_ann['SBDH'] = gpt4_ann['SBDH'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2b19c4b7-221f-45bf-a980-27fbe4ce1355",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['job insecurity' 'housing insecurity' 'violence' 'substance abuse'\n",
      " 'loss of relationship' 'barriers to care' 'pain' 'physical isolation'\n",
      " 'social isolation' 'food insecurity' 'psychiatric symptoms or disorders'\n",
      " 'financial insecurity' 'patient disability' 'transitions of care'\n",
      " 'legal problems'] ['yes' 'no'] ['current' 'unclear' 'history']\n",
      "['job insecurity' 'housing insecurity' 'violence' 'substance abuse'\n",
      " 'loss of relationship' 'barriers to care' 'pain' 'physical isolation'\n",
      " 'social isolation' 'food insecurity' 'psychiatric symptoms or disorders'\n",
      " 'financial insecurity' 'patient disability' 'transitions of care'\n",
      " 'legal problems'] ['yes' 'no'] ['current' 'unclear' 'history']\n",
      "['job insecurity' 'housing insecurity' 'violence' 'substance abuse'\n",
      " 'loss of relationship' 'barriers to care' 'pain' 'physical isolation'\n",
      " 'social isolation' 'food insecurity' 'psychiatric symptoms or disorders'\n",
      " 'financial insecurity' 'patient disability' 'transitions of care'\n",
      " 'legal problems'] ['yes' 'no'] ['current' 'unclear' 'history']\n",
      "['psychiatric symptoms or disorders' 'violence' 'transitions of care'\n",
      " 'food insecurity' 'housing insecurity' 'barriers to care'\n",
      " 'loss of relationship' 'job insecurity' 'pain' 'social isolation'\n",
      " 'financial insecurity' 'physical isolation' 'patient disability'\n",
      " 'substance abuse' 'legal problems'] ['yes'] ['current' 'history']\n"
     ]
    }
   ],
   "source": [
    "print(raelene_ann['SBDH'].unique(), raelene_ann['Presence'].unique(), raelene_ann['Period'].unique())\n",
    "print(emily_ann['SBDH'].unique(), emily_ann['Presence'].unique(), emily_ann['Period'].unique())\n",
    "print(adj_ann['SBDH'].unique(), adj_ann['Presence'].unique(), adj_ann['Period'].unique())\n",
    "print(gpt4_ann['SBDH'].unique(), gpt4_ann['Presence'].unique(), gpt4_ann['Period'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e3a9aa5a-47eb-4aaf-856b-836a92851dec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Emily-Raelene ==\n",
      "Total annotations: 224\n",
      "Matched annotations: 135(60.27%)\n",
      "Unmatched annotations: 89(39.73%)\n",
      "Matched annotations (Relaxed): 181(80.80%)\n",
      "Unmatched annotations (Relaxed): 43(19.20%)\n",
      "== Emily-GPT4 ==\n",
      "Total annotations: 209\n",
      "Matched annotations: 53(25.36%)\n",
      "Unmatched annotations: 156(74.64%)\n",
      "Matched annotations (Relaxed): 133(63.64%)\n",
      "Unmatched annotations (Relaxed): 76(36.36%)\n",
      "== Raelene-GPT4 ==\n",
      "Total annotations: 213\n",
      "Matched annotations: 48(22.54%)\n",
      "Unmatched annotations: 165(77.46%)\n",
      "Matched annotations (Relaxed): 145(68.08%)\n",
      "Unmatched annotations (Relaxed): 68(31.92%)\n",
      "== Adj-GPT4 ==\n",
      "Total annotations: 219\n",
      "Matched annotations: 56(25.57%)\n",
      "Unmatched annotations: 163(74.43%)\n",
      "Matched annotations (Relaxed): 144(65.75%)\n",
      "Unmatched annotations (Relaxed): 75(34.25%)\n"
     ]
    }
   ],
   "source": [
    "def find_contiguous_overlap(s1, s2):\n",
    "    words1 = s1.lower().split()\n",
    "    words2 = s2.lower().split()\n",
    "    \n",
    "    max_overlap = []\n",
    "    \n",
    "    for i in range(len(words1)):\n",
    "        for j in range(len(words2)):\n",
    "            temp_overlap = []\n",
    "            x, y = i, j\n",
    "            \n",
    "            while x < len(words1) and y < len(words2) and words1[x] == words2[y]:\n",
    "                temp_overlap.append(words1[x])\n",
    "                x += 1\n",
    "                y += 1\n",
    "            \n",
    "            if len(temp_overlap) > len(max_overlap):\n",
    "                max_overlap = temp_overlap\n",
    "\n",
    "    if not max_overlap: return 0\n",
    "    return len(max_overlap) if (max_overlap[0]==words1[0] or max_overlap[0]==words2[0]) else 0\n",
    "\n",
    "def get_agreement(df1, df2):\n",
    "    match, no_match = 0, 0\n",
    "    match_relaxed = 0\n",
    "    dis_df = None\n",
    "    for ex_no in df1['exmpl_no'].unique().tolist():\n",
    "        temp_df1 = df1[df1['exmpl_no']==ex_no].copy().reset_index(drop=True)[['Textspan', 'SBDH', 'Presence', 'Period']]\n",
    "        temp_df2 = df2[df2['exmpl_no']==ex_no].copy().reset_index(drop=True)[['Textspan', 'SBDH', 'Presence', 'Period']]\n",
    "        empty_df = pd.DataFrame([['---'] * len(df1.columns)], columns=df1.columns)\n",
    "        if not temp_df1.equals(temp_df2):\n",
    "            match1, match2 = [], []\n",
    "            relaxed_match1, relaxed_match2 = [], []\n",
    "            no_match_mapped1, no_match_mapped2 = [], []\n",
    "            for i in temp_df1.index:\n",
    "                for j in temp_df2.index:\n",
    "                    if temp_df1.loc[i].equals(temp_df2.loc[j]):\n",
    "                        match1 += [i]\n",
    "                        match2 += [j]\n",
    "                    # elif temp_df1.loc[i]['Textspan'].lower().strip() in temp_df2.loc[j]['Textspan'].lower().strip() or temp_df2.loc[j]['Textspan'].lower().strip() in temp_df1.loc[i]['Textspan'].lower().strip():\n",
    "                    elif find_contiguous_overlap(temp_df1.loc[i]['Textspan'].lower().strip(), temp_df2.loc[j]['Textspan'].lower().strip())>0:\n",
    "                        if temp_df1.loc[i][['SBDH', 'Presence', 'Period']].equals(temp_df2.loc[j][['SBDH', 'Presence', 'Period']]):\n",
    "                            relaxed_match1 += [i]\n",
    "                            relaxed_match2 += [j]\n",
    "                        no_match_mapped1 += [i]\n",
    "                        no_match_mapped2 += [j]\n",
    "                        # print(ex_no,i,temp_df1.loc[i]['Textspan'].lower().strip(),'||',temp_df2.loc[j]['Textspan'].lower().strip(),len(no_match_mapped1))\n",
    "            # if len(match1) == len(match2) == temp_df1.shape[0]:\n",
    "                # pass\n",
    "            if len(match1)+len(relaxed_match1) == len(match2)+len(relaxed_match2) == temp_df1.shape[0]:\n",
    "                pass\n",
    "            elif len(match1)+len(relaxed_match1)==temp_df1.shape[0]:\n",
    "                if dis_df is None:\n",
    "                    dis_df = df2[(df2['exmpl_no']==ex_no)&(~df2['ann_no'].isin(match2+relaxed_match2))].copy()\n",
    "                else:\n",
    "                    dis_df = pd.concat([dis_df,df2[(df2['exmpl_no']==ex_no)&(~df2['ann_no'].isin(match2+relaxed_match2))]])\n",
    "                dis_df = dis_df.append(empty_df, ignore_index=True)\n",
    "            elif len(match2)+len(relaxed_match2)==temp_df2.shape[0]:\n",
    "                if dis_df is None:\n",
    "                    dis_df = df1[(df1['exmpl_no']==ex_no)&(~df1['ann_no'].isin(match1+relaxed_match1))].copy()\n",
    "                else:\n",
    "                    dis_df = pd.concat([dis_df,df1[(df1['exmpl_no']==ex_no)&(~df1['ann_no'].isin(match1+relaxed_match1))]])\n",
    "                dis_df = dis_df.append(empty_df, ignore_index=True)\n",
    "            else:\n",
    "                if dis_df is None:\n",
    "                    dis_df = pd.concat([df1[(df1['exmpl_no']==ex_no)&(~df1['ann_no'].isin(match1+relaxed_match1))],df2[(df2['exmpl_no']==ex_no)&(~df2['ann_no'].isin(match2+relaxed_match2))]])\n",
    "                else:\n",
    "                    dis_df = pd.concat([dis_df,df1[(df1['exmpl_no']==ex_no)&(~df1['ann_no'].isin(match1+relaxed_match1))],df2[(df2['exmpl_no']==ex_no)&(~df2['ann_no'].isin(match2+relaxed_match2))]])\n",
    "                dis_df = dis_df.append(empty_df, ignore_index=True)\n",
    "\n",
    "            match += len(match1)\n",
    "            no_match += len(no_match_mapped1)+len(set(range(temp_df1.shape[0]))-set(match1)-set(no_match_mapped1))+len(set(range(temp_df2.shape[0]))-set(match2)-set(no_match_mapped2))\n",
    "            match_relaxed += len(match1)+len(relaxed_match1)\n",
    "        else: \n",
    "            match  += temp_df1.shape[0]\n",
    "            match_relaxed += temp_df1.shape[0]\n",
    "\n",
    "    total_ann = match+no_match\n",
    "    no_match_relaxed = total_ann - match_relaxed\n",
    "    print(f'Total annotations: {total_ann}')\n",
    "    print(f'Matched annotations: {match}({match*100/total_ann:.2f}%)')\n",
    "    print(f'Unmatched annotations: {no_match}({no_match*100/total_ann:.2f}%)')\n",
    "    print(f'Matched annotations (Relaxed): {match_relaxed}({match_relaxed*100/total_ann:.2f}%)')\n",
    "    print(f'Unmatched annotations (Relaxed): {no_match_relaxed}({no_match_relaxed*100/total_ann:.2f}%)')\n",
    "    return dis_df\n",
    "\n",
    "print('== Emily-Raelene ==')\n",
    "dis_df_er = get_agreement(raelene_ann.copy(),emily_ann.copy())\n",
    "print('== Emily-GPT4 ==')\n",
    "dis_df_eg = get_agreement(gpt4_ann.copy(),emily_ann.copy())\n",
    "print('== Raelene-GPT4 ==')\n",
    "dis_df_rg = get_agreement(raelene_ann.copy(),gpt4_ann.copy())\n",
    "print('== Adj-GPT4 ==')\n",
    "dis_df_ag = get_agreement(gpt4_ann.copy(),adj_ann.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "224841e5-dda1-47d1-9a03-06ae4ddf0611",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# display(HTML(raelene_ann[raelene_ann['exmpl_no']==818].to_html()))\n",
    "# display(HTML(gpt4_ann[gpt4_ann['exmpl_no']==899].to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "468d07e3-3b84-49bd-b7b7-85d751ad4e4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>exmpl_no</th>\n",
       "      <th>ann_no</th>\n",
       "      <th>Annotator</th>\n",
       "      <th>Text</th>\n",
       "      <th>Textspan</th>\n",
       "      <th>SBDH</th>\n",
       "      <th>Presence</th>\n",
       "      <th>Period</th>\n",
       "      <th>Reasoning</th>\n",
       "      <th>Remember</th>\n",
       "      <th>exmpl_ann_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>959</td>\n",
       "      <td>0</td>\n",
       "      <td>Emily</td>\n",
       "      <td>He is paralyzed from the waist down and requir...</td>\n",
       "      <td>paralyzed</td>\n",
       "      <td>physical isolation</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "      <td>XX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>959-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>974</td>\n",
       "      <td>1</td>\n",
       "      <td>GPT-4</td>\n",
       "      <td>Unable to secure a new job after getting laid ...</td>\n",
       "      <td>suffering from severe stress</td>\n",
       "      <td>psychiatric symptoms or disorders</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "      <td>Patient is experiencing high levels of stress,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>974</td>\n",
       "      <td>1</td>\n",
       "      <td>Emily</td>\n",
       "      <td>Unable to secure a new job after getting laid ...</td>\n",
       "      <td>laid off</td>\n",
       "      <td>job insecurity</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>974-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>980</td>\n",
       "      <td>0</td>\n",
       "      <td>GPT-4</td>\n",
       "      <td>Patient reports finding it hard to get to her ...</td>\n",
       "      <td>finding it hard to get to her doctor's office</td>\n",
       "      <td>barriers to care</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "      <td>Patient having difficulty accessing her health...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>980</td>\n",
       "      <td>0</td>\n",
       "      <td>Emily</td>\n",
       "      <td>Patient reports finding it hard to get to her ...</td>\n",
       "      <td>lack of transportation</td>\n",
       "      <td>barriers to care</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "      <td>XX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>980-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>987</td>\n",
       "      <td>0</td>\n",
       "      <td>GPT-4</td>\n",
       "      <td>The patient recently moved into a nursing home...</td>\n",
       "      <td>moved into a nursing home</td>\n",
       "      <td>transitions of care</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "      <td>Moving into a nursing home indicates transitio...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>990</td>\n",
       "      <td>0</td>\n",
       "      <td>GPT-4</td>\n",
       "      <td>Patient’s teenage son was killed in a car acci...</td>\n",
       "      <td>son was killed</td>\n",
       "      <td>loss of relationship</td>\n",
       "      <td>yes</td>\n",
       "      <td>history</td>\n",
       "      <td>The death of a child is a loss of relationship.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>990</td>\n",
       "      <td>0</td>\n",
       "      <td>Emily</td>\n",
       "      <td>Patient's teenage son was killed in a car acci...</td>\n",
       "      <td>son was killed</td>\n",
       "      <td>loss of relationship</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "      <td>XX</td>\n",
       "      <td>0.0</td>\n",
       "      <td>990-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>991</td>\n",
       "      <td>1</td>\n",
       "      <td>GPT-4</td>\n",
       "      <td>The patient is being transferred to a nursing ...</td>\n",
       "      <td>inability to perform daily activities independ...</td>\n",
       "      <td>patient disability</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "      <td>Inability to perform daily activities independ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    exmpl_no ann_no Annotator  \\\n",
       "100      959      0     Emily   \n",
       "101      ---    ---       ---   \n",
       "102      ---    ---       ---   \n",
       "103      974      1     GPT-4   \n",
       "104      974      1     Emily   \n",
       "105      ---    ---       ---   \n",
       "106      980      0     GPT-4   \n",
       "107      980      0     Emily   \n",
       "108      ---    ---       ---   \n",
       "109      987      0     GPT-4   \n",
       "110      ---    ---       ---   \n",
       "111      990      0     GPT-4   \n",
       "112      990      0     Emily   \n",
       "113      ---    ---       ---   \n",
       "114      991      1     GPT-4   \n",
       "115      ---    ---       ---   \n",
       "\n",
       "                                                  Text  \\\n",
       "100  He is paralyzed from the waist down and requir...   \n",
       "101                                                ---   \n",
       "102                                                ---   \n",
       "103  Unable to secure a new job after getting laid ...   \n",
       "104  Unable to secure a new job after getting laid ...   \n",
       "105                                                ---   \n",
       "106  Patient reports finding it hard to get to her ...   \n",
       "107  Patient reports finding it hard to get to her ...   \n",
       "108                                                ---   \n",
       "109  The patient recently moved into a nursing home...   \n",
       "110                                                ---   \n",
       "111  Patient’s teenage son was killed in a car acci...   \n",
       "112  Patient's teenage son was killed in a car acci...   \n",
       "113                                                ---   \n",
       "114  The patient is being transferred to a nursing ...   \n",
       "115                                                ---   \n",
       "\n",
       "                                              Textspan  \\\n",
       "100                                          paralyzed   \n",
       "101                                                ---   \n",
       "102                                                ---   \n",
       "103                       suffering from severe stress   \n",
       "104                                           laid off   \n",
       "105                                                ---   \n",
       "106      finding it hard to get to her doctor's office   \n",
       "107                             lack of transportation   \n",
       "108                                                ---   \n",
       "109                          moved into a nursing home   \n",
       "110                                                ---   \n",
       "111                                     son was killed   \n",
       "112                                     son was killed   \n",
       "113                                                ---   \n",
       "114  inability to perform daily activities independ...   \n",
       "115                                                ---   \n",
       "\n",
       "                                  SBDH Presence   Period  \\\n",
       "100                 physical isolation      yes  current   \n",
       "101                                ---      ---      ---   \n",
       "102                                ---      ---      ---   \n",
       "103  psychiatric symptoms or disorders      yes  current   \n",
       "104                     job insecurity      yes  current   \n",
       "105                                ---      ---      ---   \n",
       "106                   barriers to care      yes  current   \n",
       "107                   barriers to care      yes  current   \n",
       "108                                ---      ---      ---   \n",
       "109                transitions of care      yes  current   \n",
       "110                                ---      ---      ---   \n",
       "111               loss of relationship      yes  history   \n",
       "112               loss of relationship      yes  current   \n",
       "113                                ---      ---      ---   \n",
       "114                 patient disability      yes  current   \n",
       "115                                ---      ---      ---   \n",
       "\n",
       "                                             Reasoning  Remember exmpl_ann_no  \n",
       "100                                                 XX       0.0        959-0  \n",
       "101                                                ---       NaN          NaN  \n",
       "102                                                ---       NaN          NaN  \n",
       "103  Patient is experiencing high levels of stress,...       NaN          NaN  \n",
       "104                                                NaN       NaN        974-1  \n",
       "105                                                ---       NaN          NaN  \n",
       "106  Patient having difficulty accessing her health...       NaN          NaN  \n",
       "107                                                 XX       0.0        980-0  \n",
       "108                                                ---       NaN          NaN  \n",
       "109  Moving into a nursing home indicates transitio...       NaN          NaN  \n",
       "110                                                ---       NaN          NaN  \n",
       "111    The death of a child is a loss of relationship.       NaN          NaN  \n",
       "112                                                 XX       0.0        990-0  \n",
       "113                                                ---       NaN          NaN  \n",
       "114  Inability to perform daily activities independ...       NaN          NaN  \n",
       "115                                                ---       NaN          NaN  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis_df_eg.iloc[100:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ccdfccdf-8df7-4172-9142-be9ca77a112b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dis_df_er.to_csv(f'human_eval/synthetic_sbdh_annotation_text_only_adjudication.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155e5bf7-a59d-41a1-abc1-4fcd42554f43",
   "metadata": {},
   "source": [
    "##### GPT-4 generated annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ec726b1-e0a3-42d1-9bcf-743649c57249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('human_eval/sbdh_gpt4_v3_test_ann_1_consolidated.csv')\n",
    "df2 = pd.read_csv('human_eval/sbdh_gpt4_v3_test_ann_2_consolidated.csv')\n",
    "df1 = df1[df1['ex_no']>=755]\n",
    "df2 = df2[df2['ex_no']<=999]\n",
    "assert df1['ex_no'].unique().tolist() == df2['ex_no'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "970938fb-6898-4181-9f4e-4aa7ba1aed30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "match, no_match = 0, 0\n",
    "match_relaxed = 0\n",
    "dis_df = None\n",
    "for ex_no in df1['ex_no'].unique().tolist():\n",
    "    temp_df1 = df1[df1['ex_no']==ex_no].copy().reset_index(drop=True)[['Text', 'Textspan', 'SBDH', 'Presence', 'Period']]\n",
    "    temp_df2 = df2[df2['ex_no']==ex_no].copy().reset_index(drop=True)[['Text', 'Textspan', 'SBDH', 'Presence', 'Period']]\n",
    "    empty_df = pd.DataFrame([['---'] * len(df1.columns)], columns=df1.columns)\n",
    "    if not temp_df1.equals(temp_df2):\n",
    "        match1, match2 = [], []\n",
    "        relaxed_match1, relaxed_match2 = [], []\n",
    "        no_match_mapped1, no_match_mapped2 = [], []\n",
    "        for i in temp_df1.index:\n",
    "            for j in temp_df2.index:\n",
    "                if temp_df1.loc[i].equals(temp_df2.loc[j]):\n",
    "                    match1 += [i]\n",
    "                    match2 += [j]\n",
    "                elif temp_df1.loc[i]['Textspan'] in temp_df2.loc[j]['Textspan'] or temp_df2.loc[j]['Textspan'] in temp_df1.loc[i]['Textspan']:\n",
    "                    if temp_df1.loc[i][['SBDH', 'Presence', 'Period']].equals(temp_df2.loc[j][['SBDH', 'Presence', 'Period']]):\n",
    "                        relaxed_match1 += [i]\n",
    "                        relaxed_match2 += [j]\n",
    "                    no_match_mapped1 += [i]\n",
    "                    no_match_mapped2 += [j]\n",
    "        if len(match1) == len(match2) == temp_df1.shape[0]:\n",
    "            pass\n",
    "        elif len(match1)==temp_df1.shape[0]:\n",
    "            # display(temp_df2[~temp_df2.index.isin(match2)])\n",
    "            # display(df2[(df2['ex_no']==ex_no)&(~df2['ann_no'].isin(match2))])\n",
    "            if dis_df is None:\n",
    "                dis_df = df2[(df2['ex_no']==ex_no)&(~df2['ann_no'].isin(match2))].copy()\n",
    "            else:\n",
    "                dis_df = pd.concat([dis_df,df2[(df2['ex_no']==ex_no)&(~df2['ann_no'].isin(match2))]])\n",
    "            dis_df = dis_df.append(empty_df, ignore_index=True)\n",
    "        elif len(match2)==temp_df2.shape[0]:\n",
    "            # display(temp_df1[~temp_df1.index.isin(match1)])\n",
    "            # display(df1[(df1['ex_no']==ex_no)&(~df1['ann_no'].isin(match1))])\n",
    "            if dis_df is None:\n",
    "                dis_df = df1[(df1['ex_no']==ex_no)&(~df1['ann_no'].isin(match1))].copy()\n",
    "            else:\n",
    "                dis_df = pd.concat([dis_df,df1[(df1['ex_no']==ex_no)&(~df1['ann_no'].isin(match1))]])\n",
    "            dis_df = dis_df.append(empty_df, ignore_index=True)\n",
    "        else:\n",
    "            # display(pd.concat([temp_df1[~temp_df1.index.isin(match1)],temp_df2[~temp_df2.index.isin(match2)]]))\n",
    "            # display(pd.concat([df1[(df1['ex_no']==ex_no)&(~df1['ann_no'].isin(match1))],df2[(df2['ex_no']==ex_no)&(~df2['ann_no'].isin(match2))]]))\n",
    "            if dis_df is None:\n",
    "                dis_df = pd.concat([df1[(df1['ex_no']==ex_no)&(~df1['ann_no'].isin(match1))],df2[(df2['ex_no']==ex_no)&(~df2['ann_no'].isin(match2))]])\n",
    "            else:\n",
    "                dis_df = pd.concat([dis_df,df1[(df1['ex_no']==ex_no)&(~df1['ann_no'].isin(match1))],df2[(df2['ex_no']==ex_no)&(~df2['ann_no'].isin(match2))]])\n",
    "            dis_df = dis_df.append(empty_df, ignore_index=True)\n",
    "        \n",
    "        match += len(match1)\n",
    "        no_match += len(no_match_mapped1)+len(set(range(temp_df1.shape[0]))-set(match1)-set(no_match_mapped1))+len(set(range(temp_df2.shape[0]))-set(match2)-set(no_match_mapped2))\n",
    "        match_relaxed += len(match1)+len(relaxed_match1)\n",
    "    else: \n",
    "        match  += temp_df1.shape[0]\n",
    "        match_relaxed += temp_df1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52ff50ae-b6cf-4407-9131-a7a87eed6873",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total annotations: 527\n",
      "Matched annotations: 391(74.19%)\n",
      "Unmatched annotations: 136(25.81%)\n",
      "Matched annotations (Relaxed): 429(81.40%)\n",
      "Unmatched annotations (Relaxed): 98(18.60%)\n",
      "236\n"
     ]
    }
   ],
   "source": [
    "# without period\n",
    "total_ann = match+no_match\n",
    "no_match_relaxed = total_ann - match_relaxed\n",
    "print(f'Total annotations: {total_ann}')\n",
    "print(f'Matched annotations: {match}({match*100/total_ann:.2f}%)')\n",
    "print(f'Unmatched annotations: {no_match}({no_match*100/total_ann:.2f}%)')\n",
    "print(f'Matched annotations (Relaxed): {match_relaxed}({match_relaxed*100/total_ann:.2f}%)')\n",
    "print(f'Unmatched annotations (Relaxed): {no_match_relaxed}({no_match_relaxed*100/total_ann:.2f}%)')\n",
    "\n",
    "dis_df['Annotator'] = dis_df['Annotator'].apply(lambda x:'Emily' if x=='ann_1' else 'Raelene' if x=='ann_2' else x)\n",
    "print(dis_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1504,
   "id": "7187ab4f-2f14-4146-bab3-e378c0a72bab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total annotations: 527\n",
      "Matched annotations: 372(70.59%)\n",
      "Unmatched annotations: 155(29.41%)\n",
      "Matched annotations (Relaxed): 410(77.80%)\n",
      "Unmatched annotations (Relaxed): 117(22.20%)\n",
      "288\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ex_no</th>\n",
       "      <th>ann_no</th>\n",
       "      <th>Text</th>\n",
       "      <th>Textspan</th>\n",
       "      <th>SBDH</th>\n",
       "      <th>Presence</th>\n",
       "      <th>Period</th>\n",
       "      <th>Reasoning</th>\n",
       "      <th>Annotator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>760</td>\n",
       "      <td>1</td>\n",
       "      <td>XXX</td>\n",
       "      <td>XXX</td>\n",
       "      <td>XXX</td>\n",
       "      <td>XXX</td>\n",
       "      <td>XXX</td>\n",
       "      <td>XXX</td>\n",
       "      <td>Emily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>760</td>\n",
       "      <td>1</td>\n",
       "      <td>Patient has been feeling a deep sense of hopel...</td>\n",
       "      <td>skipping meals due to lack of interest</td>\n",
       "      <td>Psychiatric Symptoms or Disorders</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "      <td>Skipping meals due to lack of interest is psyc...</td>\n",
       "      <td>Raelene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>764</td>\n",
       "      <td>0</td>\n",
       "      <td>Following the death of his wife, the patient r...</td>\n",
       "      <td>death of his wife</td>\n",
       "      <td>Loss of Relationship</td>\n",
       "      <td>yes</td>\n",
       "      <td>unclear</td>\n",
       "      <td>The death of a spouse is considered a loss of ...</td>\n",
       "      <td>Emily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>764</td>\n",
       "      <td>0</td>\n",
       "      <td>Following the death of his wife, the patient r...</td>\n",
       "      <td>death of his wife</td>\n",
       "      <td>Loss of Relationship</td>\n",
       "      <td>yes</td>\n",
       "      <td>history</td>\n",
       "      <td>The death of a spouse is considered a loss of ...</td>\n",
       "      <td>Raelene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>998</td>\n",
       "      <td>0</td>\n",
       "      <td>The Veteran reports having nightmares of comba...</td>\n",
       "      <td>nightmares of combat</td>\n",
       "      <td>Psychiatric Symptoms or Disorders</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "      <td>The patient reports nightmares of combat, indi...</td>\n",
       "      <td>Emily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>998</td>\n",
       "      <td>0</td>\n",
       "      <td>The Veteran reports having nightmares of comba...</td>\n",
       "      <td>nightmares</td>\n",
       "      <td>Psychiatric Symptoms or Disorders</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "      <td>The patient reports nightmares of combat, indi...</td>\n",
       "      <td>Raelene</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>999</td>\n",
       "      <td>1</td>\n",
       "      <td>Recently, patient was discharged from the hosp...</td>\n",
       "      <td>home</td>\n",
       "      <td>Housing Insecurity</td>\n",
       "      <td>no</td>\n",
       "      <td>current</td>\n",
       "      <td>Having a home indicates lack of housing insecu...</td>\n",
       "      <td>Emily</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ex_no ann_no                                               Text  \\\n",
       "0     760      1                                                XXX   \n",
       "1     760      1  Patient has been feeling a deep sense of hopel...   \n",
       "2     ---    ---                                                ---   \n",
       "3     764      0  Following the death of his wife, the patient r...   \n",
       "4     764      0  Following the death of his wife, the patient r...   \n",
       "..    ...    ...                                                ...   \n",
       "283   998      0  The Veteran reports having nightmares of comba...   \n",
       "284   998      0  The Veteran reports having nightmares of comba...   \n",
       "285   ---    ---                                                ---   \n",
       "286   999      1  Recently, patient was discharged from the hosp...   \n",
       "287   ---    ---                                                ---   \n",
       "\n",
       "                                   Textspan  \\\n",
       "0                                       XXX   \n",
       "1    skipping meals due to lack of interest   \n",
       "2                                       ---   \n",
       "3                         death of his wife   \n",
       "4                         death of his wife   \n",
       "..                                      ...   \n",
       "283                    nightmares of combat   \n",
       "284                              nightmares   \n",
       "285                                     ---   \n",
       "286                                    home   \n",
       "287                                     ---   \n",
       "\n",
       "                                  SBDH Presence   Period  \\\n",
       "0                                  XXX      XXX      XXX   \n",
       "1    Psychiatric Symptoms or Disorders      yes  current   \n",
       "2                                  ---      ---      ---   \n",
       "3                 Loss of Relationship      yes  unclear   \n",
       "4                 Loss of Relationship      yes  history   \n",
       "..                                 ...      ...      ...   \n",
       "283  Psychiatric Symptoms or Disorders      yes  current   \n",
       "284  Psychiatric Symptoms or Disorders      yes  current   \n",
       "285                                ---      ---      ---   \n",
       "286                 Housing Insecurity       no  current   \n",
       "287                                ---      ---      ---   \n",
       "\n",
       "                                             Reasoning Annotator  \n",
       "0                                                  XXX     Emily  \n",
       "1    Skipping meals due to lack of interest is psyc...   Raelene  \n",
       "2                                                  ---       ---  \n",
       "3    The death of a spouse is considered a loss of ...     Emily  \n",
       "4    The death of a spouse is considered a loss of ...   Raelene  \n",
       "..                                                 ...       ...  \n",
       "283  The patient reports nightmares of combat, indi...     Emily  \n",
       "284  The patient reports nightmares of combat, indi...   Raelene  \n",
       "285                                                ---       ---  \n",
       "286  Having a home indicates lack of housing insecu...     Emily  \n",
       "287                                                ---       ---  \n",
       "\n",
       "[288 rows x 9 columns]"
      ]
     },
     "execution_count": 1504,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_ann = match+no_match\n",
    "no_match_relaxed = total_ann - match_relaxed\n",
    "print(f'Total annotations: {total_ann}')\n",
    "print(f'Matched annotations: {match}({match*100/total_ann:.2f}%)')\n",
    "print(f'Unmatched annotations: {no_match}({no_match*100/total_ann:.2f}%)')\n",
    "print(f'Matched annotations (Relaxed): {match_relaxed}({match_relaxed*100/total_ann:.2f}%)')\n",
    "print(f'Unmatched annotations (Relaxed): {no_match_relaxed}({no_match_relaxed*100/total_ann:.2f}%)')\n",
    "\n",
    "dis_df['Annotator'] = dis_df['Annotator'].apply(lambda x:'Emily' if x=='ann_1' else 'Raelene' if x=='ann_2' else x)\n",
    "print(dis_df.shape[0])\n",
    "dis_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1570,
   "id": "b37fdf35-64b0-42b5-b95b-988d90764c5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dis_df.to_csv(f'human_eval/sbdh_gpt4_v3_test_adjudicaion.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1577,
   "id": "ec5af309-bd58-46d5-b66c-e40d6c038e17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen's Kappa: 0.37\n",
      "Percentage agreement: 83.29\n",
      "Pearson's corrleation: 0.61\n"
     ]
    }
   ],
   "source": [
    "# Agreement || RATIONALE\n",
    "raelene_ann = pd.read_csv('human_eval/synthetic_sbdh_annotation_raelene_cmplt.csv',encoding='UTF-8')\n",
    "emily_ann = pd.read_csv('human_eval/synthetic_sbdh_annotation_emily_cmplt.csv',encoding='UTF-8')\n",
    "ann_1_rating = raelene_ann[(raelene_ann['exmpl_no']<=999)&(raelene_ann['Annotator']=='GPT-4')]['Rationale_rating'].to_numpy()\n",
    "ann_2_rating = emily_ann[(emily_ann['exmpl_no']>=755)&(emily_ann['Annotator']=='GPT-4')]['Rationale_rating'].to_numpy()\n",
    "\n",
    "print(f\"Cohen's Kappa: {cohen_kappa_score(ann_1_rating, ann_2_rating):.2f}\")\n",
    "print(f\"Percentage agreement: {sum(np.array(ann_1_rating)==np.array(ann_2_rating))*100/len(ann_2_rating):.2f}\")\n",
    "\n",
    "from numpy import corrcoef\n",
    "print(f\"Pearson's corrleation: {corrcoef([ann_1_rating,ann_2_rating])[0,1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52bdbed-3858-4861-94cc-037724990868",
   "metadata": {},
   "source": [
    "#### LLM Agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1672,
   "id": "cabdf1a8-fb2c-44c4-9adf-caba9d2d1c84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('synth_data_gpt4/synth_data_aio_filtered_8767_MSF_1_updated.json') as f: # unfortunately 34 annotations' `Corrected_Reasoning` and `Correct` fields were missing in the previous file\n",
    "    llm_eval_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1673,
   "id": "7fb5451f-c0f4-4099-a8bf-6eb016d38628",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total examples: 1,755; total annotations: 2,897\n"
     ]
    }
   ],
   "source": [
    "num_train_examples = int(len(llm_eval_data)*.7)\n",
    "num_val_examples = int(len(llm_eval_data)*.1)\n",
    "num_test_examples = len(llm_eval_data) - num_train_examples - num_val_examples\n",
    "\n",
    "random.seed(0)\n",
    "random.shuffle(llm_eval_data)\n",
    "anns = []\n",
    "for idx,i in enumerate(llm_eval_data[-num_test_examples:]):\n",
    "    for ann_idx,_ in enumerate(i['Annotations']):\n",
    "        ann = i['Annotations'][ann_idx].copy()\n",
    "        ann['ex_no'] = idx\n",
    "        ann['ann_no'] = ann_idx\n",
    "        anns += [ann]\n",
    "print(f'Total examples: {num_test_examples:,}; total annotations: {len(anns):,}')\n",
    "anns_df = pd.DataFrame(anns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1675,
   "id": "21fb27b0-7a22-4c28-a815-a3191e1d599f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yes    0.907836\n",
       "no     0.092164\n",
       "Name: Correct, dtype: float64"
      ]
     },
     "execution_count": 1675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anns_df['Correct'] = anns_df['Correct'].apply(lambda x:x.lower())\n",
    "anns_df['Correct'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1676,
   "id": "19a32a1c-9e35-452d-bf35-3c4ad43406d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Textspan</th>\n",
       "      <th>Reasoning</th>\n",
       "      <th>SBDH</th>\n",
       "      <th>Presence</th>\n",
       "      <th>Period</th>\n",
       "      <th>Text</th>\n",
       "      <th>idx</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Corrected_Reasoning</th>\n",
       "      <th>ex_no</th>\n",
       "      <th>ann_no</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lower back pain</td>\n",
       "      <td>Experiencing lower back pain is a sign of the ...</td>\n",
       "      <td>Pain</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "      <td>His lower back pain has been worsening over th...</td>\n",
       "      <td>12819</td>\n",
       "      <td>yes</td>\n",
       "      <td>The text clearly mentions that the patient is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recently been laid off</td>\n",
       "      <td>The patient lost his job recently, indicating ...</td>\n",
       "      <td>Job Insecurity</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "      <td>The patient has recently been laid off from hi...</td>\n",
       "      <td>947</td>\n",
       "      <td>yes</td>\n",
       "      <td>The patient losing his job is a clear indicati...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>concern about his financial situation</td>\n",
       "      <td>The patient is worried about his financial sit...</td>\n",
       "      <td>Financial Insecurity</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "      <td>The patient has recently been laid off from hi...</td>\n",
       "      <td>947</td>\n",
       "      <td>yes</td>\n",
       "      <td>The patient is worried about his financial sit...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>difficult to travel to the clinic</td>\n",
       "      <td>Difficulty in traveling to the clinic due to l...</td>\n",
       "      <td>Barriers to Care</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "      <td>Patient finds it difficult to travel to the cl...</td>\n",
       "      <td>3924</td>\n",
       "      <td>yes</td>\n",
       "      <td>The textspan indicates that the patient faces ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>going through a divorce</td>\n",
       "      <td>Divorce is a loss of a personal relationship.</td>\n",
       "      <td>Loss of Relationship</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "      <td>Veteran is going through a divorce and his wif...</td>\n",
       "      <td>609</td>\n",
       "      <td>yes</td>\n",
       "      <td>The text clearly mentions that the veteran is ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Textspan  \\\n",
       "0                        lower back pain   \n",
       "1                 recently been laid off   \n",
       "2  concern about his financial situation   \n",
       "3      difficult to travel to the clinic   \n",
       "4                going through a divorce   \n",
       "\n",
       "                                           Reasoning                  SBDH  \\\n",
       "0  Experiencing lower back pain is a sign of the ...                  Pain   \n",
       "1  The patient lost his job recently, indicating ...        Job Insecurity   \n",
       "2  The patient is worried about his financial sit...  Financial Insecurity   \n",
       "3  Difficulty in traveling to the clinic due to l...      Barriers to Care   \n",
       "4      Divorce is a loss of a personal relationship.  Loss of Relationship   \n",
       "\n",
       "  Presence   Period                                               Text    idx  \\\n",
       "0      yes  current  His lower back pain has been worsening over th...  12819   \n",
       "1      yes  current  The patient has recently been laid off from hi...    947   \n",
       "2      yes  current  The patient has recently been laid off from hi...    947   \n",
       "3      yes  current  Patient finds it difficult to travel to the cl...   3924   \n",
       "4      yes  current  Veteran is going through a divorce and his wif...    609   \n",
       "\n",
       "  Correct                                Corrected_Reasoning  ex_no  ann_no  \n",
       "0     yes  The text clearly mentions that the patient is ...      0       0  \n",
       "1     yes  The patient losing his job is a clear indicati...      1       0  \n",
       "2     yes  The patient is worried about his financial sit...      1       1  \n",
       "3     yes  The textspan indicates that the patient faces ...      2       0  \n",
       "4     yes  The text clearly mentions that the veteran is ...      3       0  "
      ]
     },
     "execution_count": 1676,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anns_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6551ec62-3705-45c2-bcac-82d76f15c535",
   "metadata": {},
   "source": [
    "#### Prepare adj. data in BIO+DSS+MLC format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cd895ab3-c14f-44a4-8847-7fa4d94c3207",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f395075a561d498c8f42cd1f6a4193b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/862 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>Textspan</th>\n",
       "      <th>Reasoning</th>\n",
       "      <th>SBDH</th>\n",
       "      <th>Presence</th>\n",
       "      <th>Period</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>history of substance abuse || enrolled in a su...</td>\n",
       "      <td>- || - || the patient has a history of opioid ...</td>\n",
       "      <td>substance abuse || substance abuse || substanc...</td>\n",
       "      <td>yes || yes || yes</td>\n",
       "      <td>not_current || current || not_current</td>\n",
       "      <td>Patient has a history of substance abuse, spec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>currently on parole || parole officer</td>\n",
       "      <td>- || having a parole officer indicates legal p...</td>\n",
       "      <td>legal problems || legal problems</td>\n",
       "      <td>yes || yes</td>\n",
       "      <td>current || current</td>\n",
       "      <td>Patient is currently on parole and has to meet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>has been living in a shelter</td>\n",
       "      <td>-</td>\n",
       "      <td>housing insecurity</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "      <td>Over the past few months, the patient has been...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>severe headaches</td>\n",
       "      <td>-</td>\n",
       "      <td>pain</td>\n",
       "      <td>yes</td>\n",
       "      <td>current</td>\n",
       "      <td>Patient is experiencing severe headaches and h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>facing possible jail time || possession of ill...</td>\n",
       "      <td>- || possession of illegal substances indicate...</td>\n",
       "      <td>legal problems || legal problems</td>\n",
       "      <td>yes || yes</td>\n",
       "      <td>current || current</td>\n",
       "      <td>He's facing possible jail time for possession ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>871</td>\n",
       "      <td>denies any current or past substance abuse || ...</td>\n",
       "      <td>- || - || denial of past substance abuse indic...</td>\n",
       "      <td>substance abuse || food insecurity || substanc...</td>\n",
       "      <td>not_yes || not_yes || not_yes</td>\n",
       "      <td>current || current || not_current</td>\n",
       "      <td>Patient denies any current or past substance a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>872</td>\n",
       "      <td>struggles to provide food || struggles to prov...</td>\n",
       "      <td>- || struggling to provide food and necessitie...</td>\n",
       "      <td>food insecurity || financial insecurity || soc...</td>\n",
       "      <td>yes || yes || yes</td>\n",
       "      <td>current || current || current</td>\n",
       "      <td>She is a single mother of three and struggles ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>873</td>\n",
       "      <td>feeling down || isolated || divorce</td>\n",
       "      <td>feeling down indicates presence of psychiatric...</td>\n",
       "      <td>psychiatric symptoms or disorders || social is...</td>\n",
       "      <td>yes || yes || yes</td>\n",
       "      <td>current || current || not_current</td>\n",
       "      <td>Patient reports that she has been feeling down...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>874</td>\n",
       "      <td>feels lonely and isolated || avoids social int...</td>\n",
       "      <td>- || -</td>\n",
       "      <td>social isolation || social isolation</td>\n",
       "      <td>yes || yes</td>\n",
       "      <td>current || current</td>\n",
       "      <td>Patient often feels lonely and isolated, and a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>875</td>\n",
       "      <td>struggling with alcoholism</td>\n",
       "      <td>-</td>\n",
       "      <td>substance abuse</td>\n",
       "      <td>yes</td>\n",
       "      <td>not_current</td>\n",
       "      <td>The veteran mentioned that he had been struggl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>862 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     idx                                           Textspan  \\\n",
       "0      0  history of substance abuse || enrolled in a su...   \n",
       "1      1              currently on parole || parole officer   \n",
       "2      2                       has been living in a shelter   \n",
       "3      3                                   severe headaches   \n",
       "4      4  facing possible jail time || possession of ill...   \n",
       "..   ...                                                ...   \n",
       "857  871  denies any current or past substance abuse || ...   \n",
       "858  872  struggles to provide food || struggles to prov...   \n",
       "859  873                feeling down || isolated || divorce   \n",
       "860  874  feels lonely and isolated || avoids social int...   \n",
       "861  875                         struggling with alcoholism   \n",
       "\n",
       "                                             Reasoning  \\\n",
       "0    - || - || the patient has a history of opioid ...   \n",
       "1    - || having a parole officer indicates legal p...   \n",
       "2                                                    -   \n",
       "3                                                    -   \n",
       "4    - || possession of illegal substances indicate...   \n",
       "..                                                 ...   \n",
       "857  - || - || denial of past substance abuse indic...   \n",
       "858  - || struggling to provide food and necessitie...   \n",
       "859  feeling down indicates presence of psychiatric...   \n",
       "860                                             - || -   \n",
       "861                                                  -   \n",
       "\n",
       "                                                  SBDH  \\\n",
       "0    substance abuse || substance abuse || substanc...   \n",
       "1                     legal problems || legal problems   \n",
       "2                                   housing insecurity   \n",
       "3                                                 pain   \n",
       "4                     legal problems || legal problems   \n",
       "..                                                 ...   \n",
       "857  substance abuse || food insecurity || substanc...   \n",
       "858  food insecurity || financial insecurity || soc...   \n",
       "859  psychiatric symptoms or disorders || social is...   \n",
       "860               social isolation || social isolation   \n",
       "861                                    substance abuse   \n",
       "\n",
       "                          Presence                                 Period  \\\n",
       "0                yes || yes || yes  not_current || current || not_current   \n",
       "1                       yes || yes                     current || current   \n",
       "2                              yes                                current   \n",
       "3                              yes                                current   \n",
       "4                       yes || yes                     current || current   \n",
       "..                             ...                                    ...   \n",
       "857  not_yes || not_yes || not_yes      current || current || not_current   \n",
       "858              yes || yes || yes          current || current || current   \n",
       "859              yes || yes || yes      current || current || not_current   \n",
       "860                     yes || yes                     current || current   \n",
       "861                            yes                            not_current   \n",
       "\n",
       "                                                  Text  \n",
       "0    Patient has a history of substance abuse, spec...  \n",
       "1    Patient is currently on parole and has to meet...  \n",
       "2    Over the past few months, the patient has been...  \n",
       "3    Patient is experiencing severe headaches and h...  \n",
       "4    He's facing possible jail time for possession ...  \n",
       "..                                                 ...  \n",
       "857  Patient denies any current or past substance a...  \n",
       "858  She is a single mother of three and struggles ...  \n",
       "859  Patient reports that she has been feeling down...  \n",
       "860  Patient often feels lonely and isolated, and a...  \n",
       "861  The veteran mentioned that he had been struggl...  \n",
       "\n",
       "[862 rows x 7 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_nested(range1list:list, range2list:list, verbose=False):\n",
    "    '''\n",
    "    Find if there is an intersection between elements in range1list and range2list.\n",
    "    '''\n",
    "    if len(range1list)==0 or len(range2list)==0: return False\n",
    "    for range2 in range2list:\n",
    "        for range1 in range1list:\n",
    "            if set(range(*range1)).intersection(set(range(*range2))):\n",
    "                if verbose:print(range1,range2)\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def find_sub_list(sl,l):\n",
    "    results=[]\n",
    "    sll=len(sl)\n",
    "    for ind in (i for i,e in enumerate(l) if e==sl[0]):\n",
    "        if l[ind:ind+sll]==sl:\n",
    "            results.append((ind,ind+sll))\n",
    "\n",
    "    return results\n",
    "\n",
    "split = 'val' # <<< CHECK THIS BEFORE EXECUTING THE CELL ⚠️\n",
    "\n",
    "# merge annotations into single row\n",
    "df = pd.read_csv(f'human_eval/sbdh_gpt4_v3_{split}_cmbd_consolidated.csv')\n",
    "df = df[df['Operation']!='discard'].copy() # remove unnecessary annotations\n",
    "df['Presence'] = df['Presence'].apply(lambda x: x if x=='yes' else 'not_yes')\n",
    "df['Period'] = df['Period'].apply(lambda x: x if x=='current' else 'not_current')\n",
    "\n",
    "anns_df_collapsed = pd.DataFrame(df['ex_no'].unique(),columns=['idx']).copy()\n",
    "for col in ['Textspan', 'Reasoning', 'SBDH', 'Presence', 'Period', 'Text']: \n",
    "    anns_df_collapsed[col] = 0\n",
    "    \n",
    "for i,idx in tqdm(enumerate(df['ex_no'].unique()),total=anns_df_collapsed.shape[0]):\n",
    "    temp_df = df[df['ex_no']==idx].copy()\n",
    "    assert temp_df['Text'].nunique()==1\n",
    "    for col in ['Textspan', 'Reasoning', 'SBDH', 'Presence', 'Period']:\n",
    "        assert 'XXX' not in temp_df[col].tolist()\n",
    "        anns_df_collapsed.loc[i,col] = ' || '.join(map(str.lower,temp_df[col].tolist()))\n",
    "    anns_df_collapsed.loc[i,'Text'] = temp_df.iloc[0]['Text']\n",
    "\n",
    "anns_df_collapsed = pd.DataFrame(anns_df_collapsed)\n",
    "anns_df_collapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cb54c6e7-b4ab-4bd1-ab2d-5b41a6713674",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45df567a34264f79b2c7a9664686cc6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/862 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'tokens': ['Patient', 'has', 'a', 'history', 'of', 'substance', 'abuse', ',', 'specifically', 'opioid', 'misuse', '.', 'He', 'is', 'currently', 'enrolled', 'in', 'a', 'substance', 'abuse', 'treatment', 'program', '.'], 'ner_tags': ['O', 'O', 'O', 'B-substance_abuse', 'I-substance_abuse', 'I-substance_abuse', 'I-substance_abuse', 'O', 'O', 'B-substance_abuse', 'I-substance_abuse', 'O', 'O', 'O', 'O', 'B-substance_abuse', 'I-substance_abuse', 'I-substance_abuse', 'I-substance_abuse', 'I-substance_abuse', 'I-substance_abuse', 'I-substance_abuse', 'O'], 'presence_tags': ['O', 'O', 'O', 'B-yes', 'I-yes', 'I-yes', 'I-yes', 'O', 'O', 'B-yes', 'I-yes', 'O', 'O', 'O', 'O', 'B-yes', 'I-yes', 'I-yes', 'I-yes', 'I-yes', 'I-yes', 'I-yes', 'O'], 'period_tags': ['O', 'O', 'O', 'B-not_current', 'I-not_current', 'I-not_current', 'I-not_current', 'O', 'O', 'B-not_current', 'I-not_current', 'O', 'O', 'O', 'O', 'B-current', 'I-current', 'I-current', 'I-current', 'I-current', 'I-current', 'I-current', 'O']}, {'tokens': ['Patient', 'is', 'currently', 'on', 'parole', 'and', 'has', 'to', 'meet', 'with', 'his', 'parole', 'officer', 'bi-weekly', '.'], 'ner_tags': ['O', 'O', 'B-legal_problems', 'I-legal_problems', 'I-legal_problems', 'O', 'O', 'O', 'O', 'O', 'O', 'B-legal_problems', 'I-legal_problems', 'O', 'O'], 'presence_tags': ['O', 'O', 'B-yes', 'I-yes', 'I-yes', 'O', 'O', 'O', 'O', 'O', 'O', 'B-yes', 'I-yes', 'O', 'O'], 'period_tags': ['O', 'O', 'B-current', 'I-current', 'I-current', 'O', 'O', 'O', 'O', 'O', 'O', 'B-current', 'I-current', 'O', 'O']}, {'tokens': ['Over', 'the', 'past', 'few', 'months', ',', 'the', 'patient', 'has', 'been', 'living', 'in', 'a', 'shelter', '.'], 'ner_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-housing_insecurity', 'I-housing_insecurity', 'I-housing_insecurity', 'I-housing_insecurity', 'I-housing_insecurity', 'I-housing_insecurity', 'O'], 'presence_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-yes', 'I-yes', 'I-yes', 'I-yes', 'I-yes', 'I-yes', 'O'], 'period_tags': ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-current', 'I-current', 'I-current', 'I-current', 'I-current', 'I-current', 'O']}]\n"
     ]
    }
   ],
   "source": [
    "# NER, BIO format\n",
    "bio_formatted_data = []\n",
    "for row_id in tqdm(range(anns_df_collapsed.shape[0])):\n",
    "    temp_dict = {}\n",
    "    text = word_tokenize(anns_df_collapsed.iloc[row_id]['Text'])\n",
    "    temp_dict['tokens'] = text\n",
    "    text_sbdh_tags = ['O']*len(text)\n",
    "    text_presence_tags = ['O']*len(text)\n",
    "    text_period_tags = ['O']*len(text)\n",
    "\n",
    "    sbdh_tags = [sbdh_map_dict[i].replace(' ','_') for i in anns_df_collapsed.iloc[row_id]['SBDH'].split(' || ')]\n",
    "    presence_tags = anns_df_collapsed.iloc[row_id]['Presence'].split(' || ')\n",
    "    period_tags = anns_df_collapsed.iloc[row_id]['Period'].split(' || ')\n",
    "    \n",
    "    all_sl_idxs = []\n",
    "    for i,span in enumerate(anns_df_collapsed.iloc[row_id]['Textspan'].split(' || ')):\n",
    "        textspan = word_tokenize(span)\n",
    "        sl_idxs = find_sub_list(textspan,text) \n",
    "        for idx in sl_idxs:\n",
    "            if text_sbdh_tags[idx[0]:idx[1]] == ['O']*len(textspan): # only put labels if the tokens are already unlabeled; avoiding nested labels\n",
    "                text_sbdh_tags[idx[0]] = 'B-'+sbdh_tags[i]\n",
    "                text_sbdh_tags[idx[0]+1:idx[1]] = ['I-'+sbdh_tags[i]]*(len(textspan)-1)\n",
    "                text_presence_tags[idx[0]] = 'B-'+presence_tags[i]\n",
    "                text_presence_tags[idx[0]+1:idx[1]] = ['I-'+presence_tags[i]]*(len(textspan)-1)\n",
    "                text_period_tags[idx[0]] = 'B-'+period_tags[i]\n",
    "                text_period_tags[idx[0]+1:idx[1]] = ['I-'+period_tags[i]]*(len(textspan)-1)\n",
    "                all_sl_idxs += [idx]\n",
    "    \n",
    "    if len(all_sl_idxs)>1:\n",
    "        for idx1, idx2 in zip(all_sl_idxs[:-1],all_sl_idxs[1:]):\n",
    "            if set(range(*idx1)).intersection(set(range(*idx2))): \n",
    "                print(f'Testspan overlap found at {row_id}!')\n",
    "                break\n",
    "            \n",
    "    # print(text)\n",
    "    temp_dict['ner_tags'] = text_sbdh_tags\n",
    "    temp_dict['presence_tags'] = text_presence_tags\n",
    "    temp_dict['period_tags'] = text_period_tags\n",
    "    bio_formatted_data += [temp_dict]\n",
    "    \n",
    "with open(f'synth_data_gpt4/synth_data_aio_BIO_{split}_hr.json','w') as f:\n",
    "    json.dump({'data':bio_formatted_data}, f)\n",
    "print(bio_formatted_data[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4748fc46-4031-439b-bcf1-1d9309fe93a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac562dd35ab4b0fa90b5be8d592aa2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/862 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped annotations: 45, out of 1625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'text': 'Patient has a history of substance abuse, specifically opioid misuse. He is currently enrolled in a substance abuse treatment program.',\n",
       "  'sbdh_ann': 'history of substance abuse <substance_abuse>, enrolled in a substance abuse treatment program <substance_abuse>, opioid misuse <substance_abuse>',\n",
       "  'period_ann': 'history of substance abuse <not_current>, enrolled in a substance abuse treatment program <current>, opioid misuse <not_current>',\n",
       "  'reasoning': '- - the patient has a history of opioid misuse, which is substance abuse.'},\n",
       " {'text': 'Patient is currently on parole and has to meet with his parole officer bi-weekly.',\n",
       "  'sbdh_ann': 'currently on parole <legal_problems>, parole officer <legal_problems>',\n",
       "  'period_ann': 'currently on parole <current>, parole officer <current>',\n",
       "  'reasoning': '- having a parole officer indicates legal problems.'},\n",
       " {'text': 'Over the past few months, the patient has been living in a shelter.',\n",
       "  'sbdh_ann': 'has been living in a shelter <housing_insecurity>',\n",
       "  'period_ann': 'has been living in a shelter <current>',\n",
       "  'reasoning': '-'}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DSS\n",
    "formatted_data = []\n",
    "skip_count, total_ann_count = 0, 0\n",
    "for row_id in tqdm(range(anns_df_collapsed.shape[0])):\n",
    "    temp_dict = {}\n",
    "    temp_dict['text'] = anns_df_collapsed.iloc[row_id]['Text']\n",
    "\n",
    "    sbdh_tags = [sbdh_map_dict[i].replace(' ','_') for i in anns_df_collapsed.iloc[row_id]['SBDH'].split(' || ')]\n",
    "    presence_tags = [i for i in anns_df_collapsed.iloc[row_id]['Presence'].split(' || ')]\n",
    "    period_tags = [i for i in anns_df_collapsed.iloc[row_id]['Period'].split(' || ')]\n",
    "    reasoning_tags = [i for i in anns_df_collapsed.iloc[row_id]['Reasoning'].split(' || ')]\n",
    "    # temp_dict['reasoning'] = anns_df_collapsed.iloc[row_id]['Reasoning'].replace(' || ',' ')\n",
    "    sbdh_ann, period_ann, reasoning_ann = [], [], []\n",
    "    \n",
    "    textspan_indices = []\n",
    "    for i,textspan in enumerate(anns_df_collapsed.iloc[row_id]['Textspan'].split(' || ')):\n",
    "        total_ann_count += 1\n",
    "        if presence_tags[i] == 'yes': # only consider presence=yes\n",
    "            sl_indices = find_sub_list(textspan,temp_dict['text'])\n",
    "            if is_nested(textspan_indices,sl_indices): # check for nested annotations and skip if found any\n",
    "                skip_count += 1\n",
    "                continue \n",
    "            textspan_indices += sl_indices\n",
    "            sbdh_ann += [textspan+' <'+sbdh_tags[i]+'>']\n",
    "            period_ann += [textspan+' <'+period_tags[i]+'>']\n",
    "            reasoning_ann += [reasoning_tags[i]]\n",
    "    temp_dict['sbdh_ann'] = ', '.join(sbdh_ann)\n",
    "    temp_dict['period_ann'] = ', '.join(period_ann)\n",
    "    temp_dict['reasoning'] = ' '.join(reasoning_ann)\n",
    "    formatted_data += [temp_dict]\n",
    "    # if row_id==10: break\n",
    "print(f'Skipped annotations: {skip_count}, out of {total_ann_count}')  \n",
    "\n",
    "with open(f'synth_data_gpt4/sbdh_gpt4_v3_{split}_hr.json','w') as f:\n",
    "    json.dump({'data':formatted_data}, f)\n",
    "formatted_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "93de2aaf-1cb3-4cb4-800b-6602c180690b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b728d8c8bee04bd9915523a2492d0957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/862 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total annotations: 1625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'text': 'Patient has a history of substance abuse, specifically opioid misuse. He is currently enrolled in a substance abuse treatment program.',\n",
       "  'label_barriers_to_care': 0,\n",
       "  'label_financial_insecurity': 0,\n",
       "  'label_patient_disability': 0,\n",
       "  'label_isolation_or_loss_of_relationship': 0,\n",
       "  'label_psychiatric_symptoms_or_disorders': 0,\n",
       "  'label_substance_abuse': 1,\n",
       "  'label_food_insecurity': 0,\n",
       "  'label_violence': 0,\n",
       "  'label_housing_insecurity': 0,\n",
       "  'label_pain': 0,\n",
       "  'label_legal_problems': 0,\n",
       "  'label_transitions_of_care': 0,\n",
       "  'sbdh_ann': '<substance_abuse>',\n",
       "  'reasoning': '- - the patient has a history of opioid misuse, which is substance abuse.'},\n",
       " {'text': 'Patient is currently on parole and has to meet with his parole officer bi-weekly.',\n",
       "  'label_barriers_to_care': 0,\n",
       "  'label_financial_insecurity': 0,\n",
       "  'label_patient_disability': 0,\n",
       "  'label_isolation_or_loss_of_relationship': 0,\n",
       "  'label_psychiatric_symptoms_or_disorders': 0,\n",
       "  'label_substance_abuse': 0,\n",
       "  'label_food_insecurity': 0,\n",
       "  'label_violence': 0,\n",
       "  'label_housing_insecurity': 0,\n",
       "  'label_pain': 0,\n",
       "  'label_legal_problems': 1,\n",
       "  'label_transitions_of_care': 0,\n",
       "  'sbdh_ann': '<legal_problems>',\n",
       "  'reasoning': '- having a parole officer indicates legal problems.'},\n",
       " {'text': 'Over the past few months, the patient has been living in a shelter.',\n",
       "  'label_barriers_to_care': 0,\n",
       "  'label_financial_insecurity': 0,\n",
       "  'label_patient_disability': 0,\n",
       "  'label_isolation_or_loss_of_relationship': 0,\n",
       "  'label_psychiatric_symptoms_or_disorders': 0,\n",
       "  'label_substance_abuse': 0,\n",
       "  'label_food_insecurity': 0,\n",
       "  'label_violence': 0,\n",
       "  'label_housing_insecurity': 1,\n",
       "  'label_pain': 0,\n",
       "  'label_legal_problems': 0,\n",
       "  'label_transitions_of_care': 0,\n",
       "  'sbdh_ann': '<housing_insecurity>',\n",
       "  'reasoning': '-'}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MLC\n",
    "formatted_data = []\n",
    "total_ann_count = 0\n",
    "for row_id in tqdm(range(anns_df_collapsed.shape[0])):\n",
    "    temp_dict = {}\n",
    "    temp_dict['text'] = anns_df_collapsed.iloc[row_id]['Text']\n",
    "\n",
    "    sbdh_tags = [sbdh_map_dict[i].replace(' ','_') for i in anns_df_collapsed.iloc[row_id]['SBDH'].split(' || ')]\n",
    "    presence_tags = anns_df_collapsed.iloc[row_id]['Presence'].split(' || ')\n",
    "    reasoning_tags = anns_df_collapsed.iloc[row_id]['Reasoning'].split(' || ')\n",
    "    \n",
    "    for sbdh in set(sbdh_map_dict.values()):\n",
    "        temp_dict['label_'+sbdh.replace(' ','_')] = 0\n",
    "    \n",
    "    sbdh_ann, reasoning_ann, textspan_indices = [], [], []\n",
    "    for i,_ in enumerate(presence_tags):\n",
    "        total_ann_count += 1\n",
    "        if presence_tags[i] == 'yes': # only consider presence=yes\n",
    "            temp_dict['label_'+sbdh_tags[i]] = 1\n",
    "            sbdh_ann += ['<'+sbdh_tags[i]+'>']\n",
    "            reasoning_ann += [reasoning_tags[i]]\n",
    "    temp_dict['sbdh_ann'] = ', '.join(set(sbdh_ann))\n",
    "    temp_dict['reasoning'] = ' '.join(reasoning_ann)\n",
    "    formatted_data += [temp_dict]\n",
    "print(f'Total annotations: {total_ann_count}')   \n",
    "\n",
    "with open(f'synth_data_gpt4/sbdh_gpt4_v3_multilabel_hr_{split}.json','w') as f:\n",
    "    json.dump({'data':formatted_data}, f)\n",
    "formatted_data[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f9f6e6-a32c-441d-b4f8-db865378a1ab",
   "metadata": {},
   "source": [
    "#### Convert to multi-label classification format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "b105006b-49ad-4ceb-8544-1c4b1c4d4431",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d76258cb82418383f6d452218c8d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8518 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total annotations: 13094\n"
     ]
    }
   ],
   "source": [
    "formatted_data = []\n",
    "total_ann_count = 0\n",
    "for row_id in tqdm(range(anns_df_collapsed.shape[0])):\n",
    "    temp_dict = {}\n",
    "    temp_dict['ex_no'] = anns_df_collapsed.iloc[row_id]['ex_no']\n",
    "    temp_dict['text'] = anns_df_collapsed.iloc[row_id]['Text']\n",
    "\n",
    "    sbdh_tags = [sbdh_map_dict[i].replace(' ','_') for i in anns_df_collapsed.iloc[row_id]['SBDH'].split(' || ')]\n",
    "    presence_tags = anns_df_collapsed.iloc[row_id]['Presence'].split(' || ')\n",
    "    # temp_dict['reasoning'] = anns_df_collapsed.iloc[row_id]['Corrected_Reasoning'].replace(' || ',' ')\n",
    "    reasoning_tags = [i for i in anns_df_collapsed.iloc[row_id]['Corrected_Reasoning'].split(' || ')]\n",
    "    \n",
    "    for sbdh in set(sbdh_map_dict.values()):\n",
    "        temp_dict['label_'+sbdh.replace(' ','_')] = 0\n",
    "    \n",
    "    sbdh_ann, reasoning_ann, textspan_indices = [], [], []\n",
    "    for i,_ in enumerate(presence_tags):\n",
    "        total_ann_count += 1\n",
    "        if presence_tags[i] == 'yes': # only consider presence=yes\n",
    "            temp_dict['label_'+sbdh_tags[i]] = 1\n",
    "            sbdh_ann += ['<'+sbdh_tags[i]+'>']\n",
    "            reasoning_ann += [reasoning_tags[i]]\n",
    "    temp_dict['sbdh_ann'] = ', '.join(set(sbdh_ann))\n",
    "    temp_dict['reasoning'] = ' '.join(reasoning_ann)\n",
    "    formatted_data += [temp_dict]\n",
    "print(f'Total annotations: {total_ann_count}')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "c1bdbc71-500a-4178-89b3-5a03527c71d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ex_no': 1363,\n",
       " 'text': 'The patient, currently in jail, has mentioned feeling alone and isolated.',\n",
       " 'label_barriers_to_care': 0,\n",
       " 'label_substance_abuse': 0,\n",
       " 'label_housing_insecurity': 0,\n",
       " 'label_patient_disability': 0,\n",
       " 'label_legal_problems': 1,\n",
       " 'label_food_insecurity': 0,\n",
       " 'label_transitions_of_care': 0,\n",
       " 'label_psychiatric_symptoms_or_disorders': 0,\n",
       " 'label_isolation_or_loss_of_relationship': 1,\n",
       " 'label_violence': 0,\n",
       " 'label_pain': 0,\n",
       " 'label_financial_insecurity': 0,\n",
       " 'sbdh_ann': '<isolation_or_loss_of_relationship>, <legal_problems>',\n",
       " 'reasoning': 'The patient is currently in jail which is a sign of legal problems. As per the text, the patient currently feels alone and isolated, which correctly represents a case of Social Isolation.'}"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_data[1331]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "859c0d36-4e51-421a-a308-e21a1756cb05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_barriers_to_care                      436\n",
      "label_substance_abuse                       818\n",
      "label_housing_insecurity                    804\n",
      "label_financial_insecurity                 1889\n",
      "label_psychiatric_symptoms_or_disorders    1343\n",
      "label_isolation_or_loss_of_relationship    1948\n",
      "label_patient_disability                    765\n",
      "label_violence                              614\n",
      "label_legal_problems                        444\n",
      "label_transitions_of_care                   621\n",
      "label_pain                                  866\n",
      "label_food_insecurity                       645\n",
      "dtype: int64\n",
      "8518\n"
     ]
    }
   ],
   "source": [
    "ml_sbdh_cols = [\n",
    "    'label_barriers_to_care', 'label_substance_abuse', 'label_housing_insecurity', 'label_financial_insecurity', 'label_psychiatric_symptoms_or_disorders',\n",
    "    'label_isolation_or_loss_of_relationship', 'label_patient_disability', 'label_violence', 'label_legal_problems', 'label_transitions_of_care', 'label_pain', 'label_food_insecurity'\n",
    "]\n",
    "print(pd.DataFrame(formatted_data)[ml_sbdh_cols].sum(axis=0))\n",
    "print(len(formatted_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "64e183c1-366e-4125-947a-a51419c57f16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6136 876 1755\n",
      "5965\n",
      "854\n",
      "1699\n"
     ]
    }
   ],
   "source": [
    "# v3: reordered according to aio data, corrected 'reasoning' field, v2 has erroneous (nested/presece=No) reasonings\n",
    "num_train_examples = int(len(synth_sbdh_data_filtered)*.7)\n",
    "num_val_examples = int(len(synth_sbdh_data_filtered)*.1)\n",
    "num_test_examples = len(synth_sbdh_data_filtered) - num_train_examples - num_val_examples\n",
    "print(num_train_examples, num_val_examples, num_test_examples)\n",
    "\n",
    "exmpl_order = list(range(len(synth_sbdh_data_filtered)))\n",
    "random.seed(0)\n",
    "random.shuffle(exmpl_order)\n",
    "\n",
    "df = pd.DataFrame(formatted_data)\n",
    "df.index=df['ex_no']\n",
    "\n",
    "with open('synth_data_gpt4/sbdh_gpt4_msf_v3_multilabel_train.json','w') as f:\n",
    "    new_order = [i for i in exmpl_order[:num_train_examples] if i in df['ex_no'].tolist()]\n",
    "    json.dump({'data':df.loc[new_order].to_dict(orient='records')}, f)\n",
    "    print(len(new_order))\n",
    "with open('synth_data_gpt4/sbdh_gpt4_msf_v3_multilabel_valid.json','w') as f:\n",
    "    new_order = [i for i in exmpl_order[num_train_examples:num_train_examples+num_val_examples] if i in df['ex_no'].tolist()]\n",
    "    json.dump({'data':df.loc[new_order].to_dict(orient='records')}, f)\n",
    "    print(len(new_order))\n",
    "with open('synth_data_gpt4/sbdh_gpt4_msf_v3_multilabel_test.json','w') as f:\n",
    "    new_order = [i for i in exmpl_order[-num_test_examples:] if i in df['ex_no'].tolist()]\n",
    "    json.dump({'data':df.loc[new_order].to_dict(orient='records')}, f)\n",
    "    print(len(new_order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4038ee0c-dfb2-4a09-a8fe-e1b8041cf3ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
